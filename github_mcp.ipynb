{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dec06a9",
   "metadata": {},
   "source": [
    "### Test Gtihub MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a370563d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import MCPStdioTool, ChatAgent, AgentExecutorResponse, Executor\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be03678",
   "metadata": {},
   "source": [
    "#### Connect to local github MCP server in Docker Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c5bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GITHUB_TOKEN=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\n"
     ]
    }
   ],
   "source": [
    "chat_client = OpenAIChatClient(base_url=os.getenv(\"BASE_URL\"), api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN_FULL_PERMISIONS\")\n",
    "GITHUB_HOST = \"\"\n",
    "toolsets = \"repos,issues,pull_requests,actions,code_security,experiments\"\n",
    "print(f\"GITHUB_TOKEN={GITHUB_TOKEN}\")\n",
    "github_mcp = MCPStdioTool(\n",
    "    name=\"GitHubMCP\",\n",
    "    command=\"docker\",\n",
    "    args=[\n",
    "        \"run\", \"-i\", \"--rm\",\n",
    "        \"-e\", f\"GITHUB_PERSONAL_ACCESS_TOKEN={GITHUB_TOKEN}\", f\"-e GITHUB_TOOLSETS={toolsets}\",\n",
    "        \"ghcr.io/github/github-mcp-server\"\n",
    "    ],\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "await github_mcp.connect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71486542",
   "metadata": {},
   "source": [
    "### Write comment to pull request to a repo by name and repo owner name using Github's MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1644b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "all_tools = [*github_mcp.functions]\n",
    "instructions = \"\"\"\n",
    "You are a helpful assistant that helps me write comments to the 'project-detect-secrets-in-repo' github repository with OWNER 'iuf26'. As a response only return 'SUCCESS' if operation succeeded and otherwise return 'FAILURE' and reason for failure.\n",
    "\"\"\"\n",
    "agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"ResearchAgent\",\n",
    "    tools=all_tools\n",
    " )\n",
    "result = await agent.run(\"I would like to add the 'please remove this secret number 6 1 November' comment to the pull request number 1 to the 'leaky_sample.py' file at line number 6. If there is no review started yet please do create it.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a848f7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [leaky_sample_file.py](https://github.com/iuf26/workshop-detect-secrets-in-repo/blob/feat/iulia-add-secrets/leaky_sample_file.py)\n",
      "2. [added_text_file.txt](https://github.com/iuf26/workshop-detect-secrets-in-repo/blob/feat/iulia-add-secrets/added_text_file.txt)\n"
     ]
    }
   ],
   "source": [
    "all_tools = [*github_mcp.functions]\n",
    "instructions = \"\"\"\n",
    "You are a helpful assistant. Retrieve all files included in an open pull request from the GitHub repository 'iuf26/workshop-detect-secrets-in-repo'.\n",
    "Respond only with a list of direct links (URLs) to the files changed or added in the pull request — no explanations or additional text.\n",
    "\"\"\"\n",
    "github_pr_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"PullRequestAgent\",\n",
    "    tools=all_tools\n",
    " )\n",
    "result = await github_pr_agent.run(\"Get me all the files involved in the PR with number 1.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a833801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_comment_to_pending_review\n",
      "add_issue_comment\n",
      "add_sub_issue\n",
      "assign_copilot_to_issue\n",
      "create_branch\n",
      "create_issue\n",
      "create_or_update_file\n",
      "create_pull_request\n",
      "create_repository\n",
      "delete_file\n",
      "fork_repository\n",
      "get_commit\n",
      "get_file_contents\n",
      "get_issue\n",
      "get_issue_comments\n",
      "get_label\n",
      "get_latest_release\n",
      "get_me\n",
      "get_release_by_tag\n",
      "get_tag\n",
      "get_team_members\n",
      "get_teams\n",
      "list_branches\n",
      "list_commits\n",
      "list_issue_types\n",
      "list_issues\n",
      "list_label\n",
      "list_pull_requests\n",
      "list_releases\n",
      "list_sub_issues\n",
      "list_tags\n",
      "merge_pull_request\n",
      "pull_request_read\n",
      "pull_request_review_write\n",
      "push_files\n",
      "remove_sub_issue\n",
      "reprioritize_sub_issue\n",
      "request_copilot_review\n",
      "search_code\n",
      "search_issues\n",
      "search_pull_requests\n",
      "search_repositories\n",
      "search_users\n",
      "update_issue\n",
      "update_pull_request\n",
      "update_pull_request_branch\n",
      "AssignCodingAgent\n",
      "IssueToFixWorkflow\n"
     ]
    }
   ],
   "source": [
    "for elem in github_mcp.functions:\n",
    "    print(elem.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b060a4c",
   "metadata": {},
   "source": [
    "### Paralel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c4ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send 0\n",
      "Send 1\n",
      "Send 2\n",
      "Send 3\n",
      "Send 4\n",
      "Send 5\n",
      "Send 6\n",
      "Send 7\n",
      "Send 8\n",
      "Send 9\n",
      "Producer done\n",
      "Starting producer\n",
      "Completed producer: None\n",
      "Worker worker started job 0\n",
      "Starting worker\n",
      "Worker worker started job 1\n",
      "Completed worker: None\n",
      "Worker worker started job 2\n",
      "Starting worker\n",
      "Worker worker started job 3\n",
      "Completed worker: None\n",
      "Worker worker started job 4\n",
      "Starting worker\n",
      "Worker worker started job 5\n",
      "Completed worker: None\n",
      "Worker worker started job 6\n",
      "Starting worker\n",
      "Worker worker started job 7\n",
      "Completed worker: None\n",
      "Worker worker started job 8\n",
      "Starting worker\n",
      "Worker worker started job 9\n",
      "Completed worker: None\n",
      "Starting worker\n",
      "Completed worker: None\n",
      "Starting worker\n",
      "Completed worker: None\n",
      "Starting worker\n",
      "Completed worker: None\n",
      "Starting worker\n",
      "Completed worker: None\n",
      "Starting worker\n",
      "Completed worker: None\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from agent_framework import Executor, WorkflowBuilder, handler, WorkflowContext, ConcurrentBuilder, ExecutorCompletedEvent, ExecutorInvokedEvent, WorkflowOutputEvent\n",
    "\n",
    "class Producer(Executor):\n",
    "    @handler\n",
    "    async def start(self, _: str, ctx: WorkflowContext[int]):\n",
    "        # produce 10 jobs\n",
    "        for i in range(10):\n",
    "            print(f\"Send {i}\")\n",
    "            await ctx.send_message(i)\n",
    "        print(\"Producer done\")\n",
    "\n",
    "class Worker(Executor):\n",
    "\n",
    "    @handler\n",
    "    async def handle_job(self, job_id: int, ctx: WorkflowContext[str]):\n",
    "        print(f\"Worker worker started job {job_id}\")\n",
    "        # await asyncio.sleep(2)  # simulate slow work\n",
    "        # print(f\"Worker worker finished job {job_id}\")\n",
    "        await ctx.send_message(f\"Result {job_id}\")\n",
    "\n",
    "builder = WorkflowBuilder()\n",
    "producer = Producer(\"producer\")\n",
    "worker = Worker(\"worker\")\n",
    "builder.set_start_executor(producer)\n",
    "builder.add_edge(producer, worker)\n",
    "workflow = builder.build()\n",
    "\n",
    "#workflow = ConcurrentBuilder().participants([worker, producer]).build()\n",
    "\n",
    "completion = None\n",
    "async for event in workflow.run_stream(\"start\"):\n",
    "    match event:\n",
    "        case ExecutorInvokedEvent() as invoke:\n",
    "            print(f\"Starting {invoke.executor_id}\")\n",
    "        case ExecutorCompletedEvent() as complete:\n",
    "            print(f\"Completed {complete.executor_id}: {complete.data}\")\n",
    "        case WorkflowOutputEvent() as output:\n",
    "            print(f\"Workflow produced output: {output.data}\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb5990",
   "metadata": {},
   "source": [
    "### Define Chunk processing research agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f168d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_chunks = [\n",
    "  {\n",
    "    \"chunk\": \"import os\\nDEBUG=True\\nDATABASE_URL=\\\"postgresql://appuser:Sup3rS3cret!@db:5432/app\\\"\\nJWT_SECRET=\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.fake.payload\\\"\\nADMIN_EMAIL=\\\"maria.popescu@example.ro\\\"\\nADMIN_PHONE=\\\"+40-721-555-321\\\"\\nSMTP_PASSWORD=\\\"p@55w0rd!\\\"\\nLOG_LEVEL=\\\"INFO\\\"\\nprint(\\\"config loaded\\\")\",\n",
    "    \"original_lines_interval\": [120, 128],\n",
    "    \"original_file\": \"src/app/config.py\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"# .env\\nAWS_ACCESS_KEY_ID=AKIAZZZZEXAMPLE1234\\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYZZZexample\\nS3_BUCKET=media-prod\\nSTRIPE_WEBHOOK_SECRET=whsec_1e2b3c4d5e6f7g8h9i0j\\nREDIS_URL=redis://:s3cr3tP@redis:6379/0\\n# service creds\\nSERVICE_EMAIL=ops.team@example.com\\nSERVICE_PHONE=+40-745-000-111\\nNODE_ENV=production\",\n",
    "    \"original_lines_interval\": [45, 52],\n",
    "    \"original_file\": \"services/api/.env\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"// config.js\\nmodule.exports = {\\n  stripeKey: \\\"sk_live_51NvEXAMPLEaBcD1234567890\\\",\\n  headers: {\\n    \\\"Authorization\\\": \\\"Bearer eyJraWQiOiJrZXkiLCJhbGciOiJIUzI1NiJ9.fake.token\\\",\\n    \\\"X-Api-Key\\\": \\\"b7b2f0c6-1b24-4e1a-9c1a-12e34abcd567\\\"\\n  },\\n  supportEmail: \\\"support@example.com\\\",\\n  logLevel: \\\"debug\\\"\\n};\",\n",
    "    \"original_lines_interval\": [200, 209],\n",
    "    \"original_file\": \"web/src/config.js\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"apiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: app-config\\ndata:\\n  DB_DSN: \\\"mysql://admin:hunter2@mysql:3306/app\\\"\\n  MAIL_USER: \\\"mailer@example.ro\\\"\\n  MAIL_PASS: \\\"Tr1cky-P@ss!\\\"\\n  OAUTH_CLIENT_SECRET: \\\"c0a89e5f-7d1f-4d0c-9b77-1a2b3c4d5e6f\\\"\",\n",
    "    \"original_lines_interval\": [31, 41],\n",
    "    \"original_file\": \"deploy/k8s/app-config.yaml\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"{\\n  \\\"type\\\": \\\"service_account\\\",\\n  \\\"project_id\\\": \\\"demo-proj-123\\\",\\n  \\\"private_key_id\\\": \\\"f4f3c2e1d0b9a8f7e6d5c4b3a2918171\\\",\\n  \\\"private_key\\\": \\\"-----BEGIN PRIVATE KEY-----\\\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBK...FAKE...\\\\n-----END PRIVATE KEY-----\\\\n\\\",\\n  \\\"client_email\\\": \\\"svc-acc@demo-proj-123.iam.gserviceaccount.com\\\",\\n  \\\"client_id\\\": \\\"109876543210987654321\\\",\\n  \\\"auth_uri\\\": \\\"https://accounts.google.com/o/oauth2/auth\\\"\\n}\",\n",
    "    \"original_lines_interval\": [402, 410],\n",
    "    \"original_file\": \"infra/gcp/service-account.json\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"#!/usr/bin/env bash\\nexport GITHUB_TOKEN=ghp_FAKE1234567890abcdef1234567890abcd\\nexport SLACK_BOT_TOKEN=xoxb-123456789012-1234567890123-ABCdefGHIjklMNOpqr\\ncurl -s -H \\\"Authorization: Bearer $GITHUB_TOKEN\\\" https://api.github.com/user\\ncurl -u \\\"deployer:Sup3r-Secret!\\\" https://registry.example.com/v2/_catalog\\nEMAIL_NOTIFY=\\\"andrei.ionescu@example.com\\\"\\necho \\\"Done\\\"\",\n",
    "    \"original_lines_interval\": [88, 96],\n",
    "    \"original_file\": \"scripts/release.sh\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"-- seed.sql\\nINSERT INTO users (full_name, email, phone, password_plain)\\nVALUES ('Ioana Radu','ioana.radu@example.ro','+40 722 111 222','summer2025');\\nINSERT INTO api_credentials (name, token)\\nVALUES ('internal-bot','eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.fake');\\n-- DO NOT COMMIT REAL DATA\",\n",
    "    \"original_lines_interval\": [12, 16],\n",
    "    \"original_file\": \"db/seed.sql\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"variable \\\"cloud_api_token\\\" {\\n  type = string\\n  default = \\\"tkn_live_3b2f1c4d5e6f7a8b9c0d\\\"\\n}\\nprovider \\\"example\\\" {\\n  token = var.cloud_api_token\\n}\\noutput \\\"endpoint\\\" { value = example_service.url }\",\n",
    "    \"original_lines_interval\": [77, 84],\n",
    "    \"original_file\": \"infra/terraform/vars.tf\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"spring.datasource.url=jdbc:postgresql://db:5432/app?user=app&password=Str0ngP@ss\\nspring.mail.username=mailer@example.ro\\nspring.mail.password=Qwerty!234\\njwt.signing.key=5a6b7c8d9e0f11223344556677889900\\nmanagement.endpoints.web.exposure.include=health,info,metrics\\nsupport.phone=+40-733-000-222\",\n",
    "    \"original_lines_interval\": [15, 20],\n",
    "    \"original_file\": \"service/src/main/resources/application-prod.properties\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"# notebook cell\\nOPENAI_API_KEY=\\\"sk-live-abc123XYZ987fakefakefake\\\"\\nTWILIO_ACCOUNT_SID=\\\"AC1234567890abcdef1234567890abcd\\\"\\nTWILIO_AUTH_TOKEN=\\\"9d8c7b6a5e4f3d2c1b0a\\\"\\nuser_name = \\\"Ciprian Istrate\\\"\\nuser_email = \\\"ciprian.istrate@example.com\\\"\\nprint(\\\"init done\\\")\",\n",
    "    \"original_lines_interval\": [260, 266],\n",
    "    \"original_file\": \"notebooks/exp01.ipynb\"\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b844cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "from domain.models import TextChunk\n",
    "\n",
    "NAMESPACE = uuid.UUID(\"876de125-4386-442b-9e88-d40dfbbb301d\")  # pick once & keep\n",
    "def stable_uuid(s: str) -> str:\n",
    "    s = s.strip().lower()  # normalize to avoid accidental mismatches\n",
    "    return str(uuid.uuid5(NAMESPACE, s))\n",
    "\n",
    "def shard_for_chunk(chunk: TextChunk, total_agents: int) -> int:\n",
    "    \"\"\"\n",
    "    Pick which worker (0..total_agents-1) should handle this chunk.\n",
    "\n",
    "    How it works (in plain words):\n",
    "    - Build a key from the file name and line range (e.g., \"app.py|120|180\").\n",
    "    - Hash that key with SHA-256 (gives a big, stable number).\n",
    "    - Take that number modulo total_agents to get a shard index.\n",
    "\n",
    "    Inputs:\n",
    "    - chunk: has `source_file: str` and `line_span: (start:int, end:int)`.\n",
    "    - total_agents: number of workers; must be >= 1.\n",
    "\n",
    "    Guarantees:\n",
    "    - Same chunk → same shard index (deterministic).\n",
    "    - Result r is an int with 0 <= r < total_agents.\n",
    "\n",
    "    Example:\n",
    "    >> shard_for_chunk(TextChunk(source_file=\"a.py\", line_span=(10, 30)), total_agents=3)\n",
    "    2\n",
    "    \"\"\"\n",
    "    h = hashlib.sha256(f\"{chunk.source_file}|{chunk.line_span}\".encode()).digest()\n",
    "    return int.from_bytes(h[:4], \"big\") % total_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2959b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import Executor, WorkflowBuilder, handler, WorkflowContext, ConcurrentBuilder, ChatAgent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from domain.models import TextChunk, LineComment, SecretsDetectorExecutorResponse, EmptySecretsDetectorExecutorResponseFactory\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "chat_client = OpenAIChatClient(base_url=os.getenv(\"BASE_URL\"), api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_PAT\")\n",
    "\n",
    "class SecretsDetectorExec(Executor):\n",
    "    agent: ChatAgent\n",
    "    agent_instruction = \"\"\"\n",
    "        <instruction role=\"system\">\n",
    "        You are a code-secrets detector. Given a text CHUNK (with \"\\n\" newlines) and its original line interval [START, END], return only a JSON array of findings. Flag lines that contain likely secrets (API keys/tokens, private keys, passwords, connection strings with creds, service-account JSON fields, auth headers) or PII (names paired with email/phone/IDs). Be precise; if unsure, don't flag. Ignore obvious placeholders.\n",
    "        </instruction>\n",
    "        <schema>\n",
    "        Output exactly:\n",
    "        [\n",
    "        { \"line_number\": <int original line>, \"comment\": \"<types comma-separated>. Please remove.\" }\n",
    "        ]\n",
    "        Return [] if nothing is found. No extra text.\n",
    "        </schema>\n",
    "        <procedure>\n",
    "        1) Split CHUNK by \"\\n\".\n",
    "        2) For each line i (1-based), assess for secrets/PII using field names and context (e.g., \"api_key\", \"token\", \"password\", \"private_key\", DSN with user:pass, \"Authorization: Bearer ...\", service-account fields like private_key_id/private_key).\n",
    "        3) If flagged, compute original line_number = START + i - 1.\n",
    "        4) Emit JSON as per <schema>, comments short, no code excerpts.\n",
    "        </procedure>\n",
    "        <example>\n",
    "        INPUT:\n",
    "        START=4, END=7\n",
    "        CHUNK:\n",
    "        print(\"ok\")\n",
    "        \"private_key_id\": \"f4f3c2e1d0b9a8f7e6d5c4b3a2918171\",\n",
    "        print(\"done\")\n",
    "\n",
    "        OUTPUT:\n",
    "        [\n",
    "        { \"line_number\": 5, \"comment\": \"Private key identifier. Please remove.\" }\n",
    "        ]\n",
    "        </example>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chat_client: OpenAIChatClient,  my_shard: int, total_agents: int, id: str = \"secrets detector\"):\n",
    "        agent = chat_client.create_agent(\n",
    "            instructions=self.agent_instruction,\n",
    "            name=f\"SecretsDetectorAgent_{id}\",\n",
    "        )\n",
    "        self.id = id\n",
    "        self.agent = agent\n",
    "        self.my_shard = my_shard\n",
    "        self.total_agents = total_agents\n",
    "        super().__init__(agent=agent, id=id)\n",
    "    \n",
    "    def create_prompt_from_chunk(self, chunk: TextChunk):\n",
    "        prompt = f\"\"\"\n",
    "            Please investigate and detect secrets existent in the chunk taken from the line intervals of the file {chunk.source_file}.\n",
    "            INPUT\n",
    "            START={chunk.line_span[0]}, END={chunk.line_span[1]}\n",
    "            CHUNK:\n",
    "            {chunk.text}\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    \n",
    "    @handler\n",
    "    async def run(self, chunk: TextChunk,ctx: WorkflowContext[SecretsDetectorExecutorResponse]) -> None:\n",
    "        print(shard_for_chunk(chunk, self.total_agents))\n",
    "        if shard_for_chunk(chunk, self.total_agents) != self.my_shard:\n",
    "            return\n",
    "        prompt = self.create_prompt_from_chunk(chunk)\n",
    "        key = stable_uuid(repr((chunk.source_file, chunk.line_span)))\n",
    "\n",
    "        async with ctx.shared_state.hold():\n",
    "            chunk_processed = await ctx.shared_state.get_within_hold(key)\n",
    "            if chunk_processed:\n",
    "                await ctx.send_message(EmptySecretsDetectorExecutorResponseFactory.get_empty_secrets_detector())\n",
    "                return\n",
    "            await ctx.shared_state.set_within_hold(key, True)\n",
    "        response = await self.agent.run(prompt)\n",
    "        identified_problematic_lines = [LineComment(line_number=elem[\"line_number\"], comment=elem[\"comment\"]) for elem in json.loads(response.text)]\n",
    "        await ctx.set_shared_state(key, True)\n",
    "        await ctx.send_message(SecretsDetectorExecutorResponse(comments=identified_problematic_lines, original_file=chunk.source_file, executor_agent=self.id))\n",
    "\n",
    "\n",
    "class ChunksExporterExec(Executor):\n",
    "    def __init__(self, id):\n",
    "         self.id = id\n",
    "         super().__init__(id=id)\n",
    "    @handler\n",
    "    async def run(self, _: str,ctx: WorkflowContext[TextChunk]) -> None:\n",
    "        \"\"\"Sends input test chunks\"\"\"\n",
    "        for chunk in input_test_chunks:\n",
    "            start, end = chunk[\"original_lines_interval\"]\n",
    "            text_chunk = TextChunk(chunk=str(chunk[\"chunk\"]), \n",
    "                                             line_span=(int(start), int(end)), \n",
    "                                             source_file=str(chunk[\"original_file\"]),\n",
    "                                             )\n",
    "            key = stable_uuid(repr((text_chunk.source_file, text_chunk.line_span)))\n",
    "            await ctx.set_shared_state(key, False)\n",
    "            await ctx.send_message(text_chunk)\n",
    "\n",
    "class ChunksAgregatorExec(Executor):\n",
    "    @handler\n",
    "    async def run(self, detected_secrets: list[SecretsDetectorExecutorResponse] ,ctx: WorkflowContext[None]) -> None:\n",
    "        \"\"\"Sends input test chunks\"\"\"\n",
    "        filtered_nonempty = [secret for secret in detected_secrets if not secret.is_empty()]\n",
    "        print(datetime.now(), filtered_nonempty)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea32faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_chat_client = chat_client\n",
    "total_agents=3\n",
    "secrets_detector_1 = SecretsDetectorExec(openai_chat_client,id=\"SecretsDetector1\", my_shard=0, total_agents=total_agents)\n",
    "secrets_detector_2 = SecretsDetectorExec(openai_chat_client, id=\"SecretsDetector2\", my_shard=1, total_agents=total_agents)\n",
    "secrets_detector_3 = SecretsDetectorExec(openai_chat_client, id=\"SecretsDetector3\", my_shard=2, total_agents=total_agents)\n",
    "exporter = ChunksExporterExec(id=\"ChunkExporterAgent\")\n",
    "aggregator = ChunksAgregatorExec(id=\"ChunksAgregatorAgent\")\n",
    "builder = WorkflowBuilder()\n",
    "builder.set_start_executor(exporter)\n",
    "builder.add_fan_out_edges(exporter, [secrets_detector_1, secrets_detector_2, secrets_detector_3])\n",
    "builder.add_fan_in_edges([secrets_detector_1,\n",
    "                          secrets_detector_2,\n",
    "                          secrets_detector_3],\n",
    "                         aggregator)\n",
    "workflow = builder.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d20c605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2025-11-04 20:41:54.161173 [SecretsDetectorExecutorResponse(comments=[LineComment(line_number=404, comment='Private key identifier. Please remove.'), LineComment(line_number=405, comment='Private key. Please remove.'), LineComment(line_number=406, comment='Client email. Please remove.')], original_file='infra/gcp/service-account.json', executor_agent='SecretsDetector1'), SecretsDetectorExecutorResponse(comments=[LineComment(line_number=89, comment='GitHub token. Please remove.'), LineComment(line_number=90, comment='Slack bot token. Please remove.'), LineComment(line_number=91, comment='Authorization header with GitHub token. Please remove.'), LineComment(line_number=92, comment='Username and password in connection string. Please remove.'), LineComment(line_number=93, comment='Email address. Please remove.')], original_file='scripts/release.sh', executor_agent='SecretsDetector2'), SecretsDetectorExecutorResponse(comments=[LineComment(line_number=123, comment='Connection string with credentials. Please remove.'), LineComment(line_number=124, comment='JWT secret. Please remove.'), LineComment(line_number=126, comment='Password. Please remove.'), LineComment(line_number=125, comment='Personally identifiable information (email). Please remove.'), LineComment(line_number=126, comment='Personally identifiable information (phone). Please remove.')], original_file='src/app/config.py', executor_agent='SecretsDetector3')]\n",
      "2025-11-04 20:41:54.162005 [SecretsDetectorExecutorResponse(comments=[LineComment(line_number=261, comment='API key. Please remove.'), LineComment(line_number=262, comment='Account SID. Please remove.'), LineComment(line_number=263, comment='Authentication token. Please remove.'), LineComment(line_number=264, comment='Name with email. Please remove.')], original_file='notebooks/exp01.ipynb', executor_agent='SecretsDetector1'), SecretsDetectorExecutorResponse(comments=[LineComment(line_number=78, comment='API token. Please remove.')], original_file='infra/terraform/vars.tf', executor_agent='SecretsDetector2'), SecretsDetectorExecutorResponse(comments=[LineComment(line_number=46, comment='AWS access key ID. Please remove.'), LineComment(line_number=47, comment='AWS secret access key. Please remove.'), LineComment(line_number=48, comment='Stripe webhook secret. Please remove.'), LineComment(line_number=49, comment='Redis connection string with credentials. Please remove.'), LineComment(line_number=50, comment='Email address. Please remove.'), LineComment(line_number=51, comment='Phone number. Please remove.')], original_file='services/api/.env', executor_agent='SecretsDetector3')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ExecutorInvokedEvent(executor_id=ChunkExporterAgent, data=None),\n",
       " ExecutorCompletedEvent(executor_id=ChunkExporterAgent, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector2, data=None),\n",
       " ExecutorInvokedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector3, data=None),\n",
       " ExecutorCompletedEvent(executor_id=SecretsDetector1, data=None),\n",
       " ExecutorInvokedEvent(executor_id=ChunksAgregatorAgent, data=None),\n",
       " ExecutorCompletedEvent(executor_id=ChunksAgregatorAgent, data=None),\n",
       " ExecutorInvokedEvent(executor_id=ChunksAgregatorAgent, data=None),\n",
       " ExecutorCompletedEvent(executor_id=ChunksAgregatorAgent, data=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await workflow.run(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-demo-Op3ouSUd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
