{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dec06a9",
   "metadata": {},
   "source": [
    "## Part 1: Experiment interaction with Gtihub MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be03678",
   "metadata": {},
   "source": [
    "#### Example: Run GitHub MCP server locally in Docker\n",
    "The following code loads environment settings, spins up an OpenAI chat client, and launches GitHub’s MCP server inside Docker so the agent can call GitHub tools.\n",
    "\n",
    "dotenv pulls in API keys and MCP settings from .env.\n",
    "OpenAIChatClient is configured with your custom base URL/model so every MCP call uses that backend.\n",
    "\n",
    "The MCP tool definition wraps docker run; it injects the GitHub PAT plus the list of toolsets the server should expose.\n",
    "await github_mcp.connect() starts the Docker container and establishes the socket so subsequent ChatAgent runs can invoke GitHub functions (repos, PRs, issues, etc.) through the MCP layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c5bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import MCPStdioTool, ChatAgent\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "chat_client = OpenAIChatClient(base_url=os.getenv(\"BASE_URL\"), api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN_FULL_PERMISIONS\")\n",
    "GITHUB_HOST = \"\"\n",
    "toolsets = \"repos,issues,pull_requests,actions,code_security,experiments\"\n",
    "github_mcp = MCPStdioTool(\n",
    "    name=\"GitHubMCP\",\n",
    "    command=\"docker\",\n",
    "    args=[\n",
    "        \"run\", \"-i\", \"--rm\",\n",
    "        \"-e\", f\"GITHUB_PERSONAL_ACCESS_TOKEN={GITHUB_TOKEN}\", f\"-e GITHUB_TOOLSETS={toolsets}\",\n",
    "        \"ghcr.io/github/github-mcp-server\"\n",
    "    ],\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "await github_mcp.connect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71486542",
   "metadata": {},
   "source": [
    "### Example: Write comment to a pull request using Github's MCP server\n",
    "\n",
    "This block wires the GitHub MCP tools into a task‑specific agent that leaves a review comment on a pull request.\n",
    "\n",
    "all_tools = [*github_mcp.functions] expands every capability exposed by the connected MCP server (issues, PR reviews, etc.).\n",
    "\n",
    "The instructions string plays system prompt: the agent must operate only on iuf26/workshop-project-detect-secrets-in-repo and reply with SUCCESS or FAILURE.\n",
    "\n",
    "ChatAgent binds those instructions, the shared chat_client, and the MCP tool list into a named agent (ResearchAgent).\n",
    "\n",
    "The await agent.run(...) call triggers one conversational turn where the agent visits PR #1, starts a review if needed, and posts the requested comment on leaky_sample.py line 6; the printed result is just SUCCESS or FAILURE + reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "all_tools = [*github_mcp.functions]\n",
    "instructions = \"\"\"\n",
    "You are a helpful assistant that helps me write comments to the 'workshop-project-detect-secrets-in-repo' github repository with OWNER 'iuf26'. As a response only return 'SUCCESS' if operation succeeded and otherwise return 'FAILURE' and reason for failure.\n",
    "\"\"\"\n",
    "agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"ResearchAgent\",\n",
    "    tools=all_tools\n",
    " )\n",
    "result = await agent.run(\"I would like to add the 'please remove this secret number 6 1 November' comment to the pull request number 1 to the 'leaky_sample.py' file at line number 6. If there is no review started yet please do create it.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1ccf7",
   "metadata": {},
   "source": [
    "### Example: Retrieve all files from a PR using GitHub MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a848f7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [leaky_sample_file.py](https://github.com/iuf26/workshop-detect-secrets-in-repo/blob/feat/iulia-add-secrets/leaky_sample_file.py)\n",
      "2. [added_text_file.txt](https://github.com/iuf26/workshop-detect-secrets-in-repo/blob/feat/iulia-add-secrets/added_text_file.txt)\n"
     ]
    }
   ],
   "source": [
    "all_tools = [*github_mcp.functions]\n",
    "instructions = \"\"\"\n",
    "You are a helpful assistant. Retrieve all files included in an open pull request from the GitHub repository 'iuf26/workshop-detect-secrets-in-repo'.\n",
    "Respond only with a list of direct links (URLs) to the files changed or added in the pull request — no explanations or additional text.\n",
    "\"\"\"\n",
    "github_pr_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"PullRequestAgent\",\n",
    "    tools=all_tools\n",
    " )\n",
    "result = await github_pr_agent.run(\"Get me all the files involved in the PR with number 1.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef2837",
   "metadata": {},
   "source": [
    "### Example: List all github mcp server tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a833801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_comment_to_pending_review\n",
      "add_issue_comment\n",
      "add_sub_issue\n",
      "assign_copilot_to_issue\n",
      "create_branch\n",
      "create_issue\n",
      "create_or_update_file\n",
      "create_pull_request\n",
      "create_repository\n",
      "delete_file\n",
      "fork_repository\n",
      "get_commit\n",
      "get_file_contents\n",
      "get_issue\n",
      "get_issue_comments\n",
      "get_label\n",
      "get_latest_release\n",
      "get_me\n",
      "get_release_by_tag\n",
      "get_tag\n",
      "get_team_members\n",
      "get_teams\n",
      "list_branches\n",
      "list_commits\n",
      "list_issue_types\n",
      "list_issues\n",
      "list_label\n",
      "list_pull_requests\n",
      "list_releases\n",
      "list_sub_issues\n",
      "list_tags\n",
      "merge_pull_request\n",
      "pull_request_read\n",
      "pull_request_review_write\n",
      "push_files\n",
      "remove_sub_issue\n",
      "reprioritize_sub_issue\n",
      "request_copilot_review\n",
      "search_code\n",
      "search_issues\n",
      "search_pull_requests\n",
      "search_repositories\n",
      "search_users\n",
      "update_issue\n",
      "update_pull_request\n",
      "update_pull_request_branch\n",
      "AssignCodingAgent\n",
      "IssueToFixWorkflow\n"
     ]
    }
   ],
   "source": [
    "for elem in github_mcp.functions:\n",
    "    print(elem.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74eac9",
   "metadata": {},
   "source": [
    "## Part 2: Implement agentic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb5990",
   "metadata": {},
   "source": [
    "### Define Chunk processing research agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f168d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_chunks = [\n",
    "  {\n",
    "    \"chunk\": \"import os\\nDEBUG=True\\nDATABASE_URL=\\\"postgresql://appuser:Sup3rS3cret!@db:5432/app\\\"\\nJWT_SECRET=\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.fake.payload\\\"\\nADMIN_EMAIL=\\\"maria.popescu@example.ro\\\"\\nADMIN_PHONE=\\\"+40-721-555-321\\\"\\nSMTP_PASSWORD=\\\"p@55w0rd!\\\"\\nLOG_LEVEL=\\\"INFO\\\"\\nprint(\\\"config loaded\\\")\",\n",
    "    \"original_lines_interval\": [120, 128],\n",
    "    \"original_file\": \"src/app/config.py\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"# .env\\nAWS_ACCESS_KEY_ID=AKIAZZZZEXAMPLE1234\\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYZZZexample\\nS3_BUCKET=media-prod\\nSTRIPE_WEBHOOK_SECRET=whsec_1e2b3c4d5e6f7g8h9i0j\\nREDIS_URL=redis://:s3cr3tP@redis:6379/0\\n# service creds\\nSERVICE_EMAIL=ops.team@example.com\\nSERVICE_PHONE=+40-745-000-111\\nNODE_ENV=production\",\n",
    "    \"original_lines_interval\": [45, 52],\n",
    "    \"original_file\": \"services/api/.env\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"// config.js\\nmodule.exports = {\\n  stripeKey: \\\"sk_live_51NvEXAMPLEaBcD1234567890\\\",\\n  headers: {\\n    \\\"Authorization\\\": \\\"Bearer eyJraWQiOiJrZXkiLCJhbGciOiJIUzI1NiJ9.fake.token\\\",\\n    \\\"X-Api-Key\\\": \\\"b7b2f0c6-1b24-4e1a-9c1a-12e34abcd567\\\"\\n  },\\n  supportEmail: \\\"support@example.com\\\",\\n  logLevel: \\\"debug\\\"\\n};\",\n",
    "    \"original_lines_interval\": [200, 209],\n",
    "    \"original_file\": \"web/src/config.js\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"apiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: app-config\\ndata:\\n  DB_DSN: \\\"mysql://admin:hunter2@mysql:3306/app\\\"\\n  MAIL_USER: \\\"mailer@example.ro\\\"\\n  MAIL_PASS: \\\"Tr1cky-P@ss!\\\"\\n  OAUTH_CLIENT_SECRET: \\\"c0a89e5f-7d1f-4d0c-9b77-1a2b3c4d5e6f\\\"\",\n",
    "    \"original_lines_interval\": [31, 41],\n",
    "    \"original_file\": \"deploy/k8s/app-config.yaml\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"{\\n  \\\"type\\\": \\\"service_account\\\",\\n  \\\"project_id\\\": \\\"demo-proj-123\\\",\\n  \\\"private_key_id\\\": \\\"f4f3c2e1d0b9a8f7e6d5c4b3a2918171\\\",\\n  \\\"private_key\\\": \\\"-----BEGIN PRIVATE KEY-----\\\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBK...FAKE...\\\\n-----END PRIVATE KEY-----\\\\n\\\",\\n  \\\"client_email\\\": \\\"svc-acc@demo-proj-123.iam.gserviceaccount.com\\\",\\n  \\\"client_id\\\": \\\"109876543210987654321\\\",\\n  \\\"auth_uri\\\": \\\"https://accounts.google.com/o/oauth2/auth\\\"\\n}\",\n",
    "    \"original_lines_interval\": [402, 410],\n",
    "    \"original_file\": \"infra/gcp/service-account.json\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"#!/usr/bin/env bash\\nexport GITHUB_TOKEN=ghp_FAKE1234567890abcdef1234567890abcd\\nexport SLACK_BOT_TOKEN=xoxb-123456789012-1234567890123-ABCdefGHIjklMNOpqr\\ncurl -s -H \\\"Authorization: Bearer $GITHUB_TOKEN\\\" https://api.github.com/user\\ncurl -u \\\"deployer:Sup3r-Secret!\\\" https://registry.example.com/v2/_catalog\\nEMAIL_NOTIFY=\\\"andrei.ionescu@example.com\\\"\\necho \\\"Done\\\"\",\n",
    "    \"original_lines_interval\": [88, 96],\n",
    "    \"original_file\": \"scripts/release.sh\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"-- seed.sql\\nINSERT INTO users (full_name, email, phone, password_plain)\\nVALUES ('Ioana Radu','ioana.radu@example.ro','+40 722 111 222','summer2025');\\nINSERT INTO api_credentials (name, token)\\nVALUES ('internal-bot','eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.fake');\\n-- DO NOT COMMIT REAL DATA\",\n",
    "    \"original_lines_interval\": [12, 16],\n",
    "    \"original_file\": \"db/seed.sql\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"variable \\\"cloud_api_token\\\" {\\n  type = string\\n  default = \\\"tkn_live_3b2f1c4d5e6f7a8b9c0d\\\"\\n}\\nprovider \\\"example\\\" {\\n  token = var.cloud_api_token\\n}\\noutput \\\"endpoint\\\" { value = example_service.url }\",\n",
    "    \"original_lines_interval\": [77, 84],\n",
    "    \"original_file\": \"infra/terraform/vars.tf\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"spring.datasource.url=jdbc:postgresql://db:5432/app?user=app&password=Str0ngP@ss\\nspring.mail.username=mailer@example.ro\\nspring.mail.password=Qwerty!234\\njwt.signing.key=5a6b7c8d9e0f11223344556677889900\\nmanagement.endpoints.web.exposure.include=health,info,metrics\\nsupport.phone=+40-733-000-222\",\n",
    "    \"original_lines_interval\": [15, 20],\n",
    "    \"original_file\": \"service/src/main/resources/application-prod.properties\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"# notebook cell\\nOPENAI_API_KEY=\\\"sk-live-abc123XYZ987fakefakefake\\\"\\nTWILIO_ACCOUNT_SID=\\\"AC1234567890abcdef1234567890abcd\\\"\\nTWILIO_AUTH_TOKEN=\\\"9d8c7b6a5e4f3d2c1b0a\\\"\\nuser_name = \\\"Ciprian Istrate\\\"\\nuser_email = \\\"ciprian.istrate@example.com\\\"\\nprint(\\\"init done\\\")\",\n",
    "    \"original_lines_interval\": [260, 266],\n",
    "    \"original_file\": \"notebooks/exp01.ipynb\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df6b45",
   "metadata": {},
   "source": [
    "### Test split chunk\n",
    "Split sample file that is found in the PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9244b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "def split_file_by_newlines(\n",
    "    file_path: str,\n",
    "    newlines_per_chunk: int,\n",
    "    pull_request_number: str = \"\",\n",
    "    repo: str = \"\",\n",
    "    repo_owner: str = \"\",\n",
    ") -> List[Dict]:\n",
    "    \"\"\" \n",
    "    Split a text file into chunks containing a fixed number of newline separators.\n",
    "    - Normalizes all line endings to '\\n' first.\n",
    "    - `original_lines_interval` is 1-based and inclusive.\n",
    "    - If the last chunk has fewer lines (fewer '\\n' separators), it's still included.\n",
    "    \"\"\"\n",
    "    p = Path(file_path)\n",
    "    original_file = p.name\n",
    "\n",
    "    # Normalize all newlines to '\\n' to ensure consistent splitting\n",
    "    text = p.read_text(encoding=\"utf-8\", errors=\"replace\").replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # Split strictly by '\\n'\n",
    "    lines = text.split(\"\\n\")  # newline characters are removed by split\n",
    "    total_lines = len(lines)\n",
    "\n",
    "    chunks: List[Dict] = []\n",
    "\n",
    "    # Step through in blocks of `newlines_per_chunk` lines\n",
    "    for i in range(0, total_lines, newlines_per_chunk):\n",
    "        block = lines[i : i + newlines_per_chunk]\n",
    "        if not block:\n",
    "            continue\n",
    "\n",
    "        # Reconstruct the chunk string with '\\n' between lines.\n",
    "        # IMPORTANT: we DO NOT append a trailing '\\n' at the end of the chunk.\n",
    "        chunk_text = \"\\n\".join(block)\n",
    "\n",
    "        # 1-based line numbers for the original interval\n",
    "        start_line = i + 1\n",
    "        end_line = i + len(block)\n",
    "\n",
    "        chunks.append({\n",
    "            \"chunk\": chunk_text,\n",
    "            \"original_lines_interval\": [start_line, end_line],\n",
    "            \"original_file\": original_file,\n",
    "            \"pull_request_number\": pull_request_number,\n",
    "            \"repo\": repo,\n",
    "            \"repo_owner\": repo_owner,\n",
    "        })\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522e7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_chunks = split_file_by_newlines(\"samples/leaky_sample.py\",10,\"1\",repo=\"workshop-detect-secrets-in-repo\",repo_owner=\"iuf26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b844cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "from domain.models import TextChunk\n",
    "\n",
    "NAMESPACE = uuid.UUID(\"876de125-4386-442b-9e88-d40dfbbb301d\")  # pick once & keep\n",
    "def stable_uuid(s: str) -> str:\n",
    "    s = s.strip().lower()  # normalize to avoid accidental mismatches\n",
    "    return str(uuid.uuid5(NAMESPACE, s))\n",
    "\n",
    "def shard_for_chunk(chunk: TextChunk, total_agents: int) -> int:\n",
    "    \"\"\"\n",
    "    Pick which worker (0..total_agents-1) should handle this chunk.\n",
    "\n",
    "    How it works (in plain words):\n",
    "    - Build a key from the file name and line range (e.g., \"app.py|120|180\").\n",
    "    - Hash that key with SHA-256 (gives a big, stable number).\n",
    "    - Take that number modulo total_agents to get a shard index.\n",
    "\n",
    "    Inputs:\n",
    "    - chunk: has `source_file: str` and `line_span: (start:int, end:int)`.\n",
    "    - total_agents: number of workers; must be >= 1.\n",
    "\n",
    "    Guarantees:\n",
    "    - Same chunk → same shard index (deterministic).\n",
    "    - Result r is an int with 0 <= r < total_agents.\n",
    "\n",
    "    Example:\n",
    "    >> shard_for_chunk(TextChunk(source_file=\"a.py\", line_span=(10, 30)), total_agents=3)\n",
    "    2\n",
    "    \"\"\"\n",
    "    h = hashlib.sha256(f\"{chunk.source_file}|{chunk.line_span}\".encode()).digest()\n",
    "    return int.from_bytes(h[:4], \"big\") % total_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agent_framework import Executor, WorkflowBuilder, WorkflowEvent, handler, WorkflowContext, ChatAgent, ExecutorInvokedEvent, ExecutorCompletedEvent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "import json\n",
    "from domain.models import TextChunk, LineComment, SecretsDetectorExecutorResponse, EmptySecretsDetectorExecutorResponseFactory\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "chat_client = OpenAIChatClient(base_url=os.getenv(\"BASE_URL\"), api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_PAT\")\n",
    "DETECTED_SECRETS_RESULT_KEY = \"detected_secrets\"\n",
    "\n",
    "class CustomResponseEvent(WorkflowEvent):\n",
    "    def __init__(self, result: list[SecretsDetectorExecutorResponse]):\n",
    "        super().__init__(result)\n",
    "\n",
    "class SecretsDetectorExec(Executor):\n",
    "    agent: ChatAgent\n",
    "    agent_instruction = \"\"\"\n",
    "        <instruction role=\"system\">\n",
    "        You are a code-secrets detector. Given a text CHUNK (with \"\\n\" newlines) and its original line interval [START, END], return only a JSON array of findings. Flag lines that contain likely secrets (API keys/tokens, private keys, passwords, connection strings with creds, service-account JSON fields, auth headers) or PII (names paired with email/phone/IDs). Be precise; if unsure, don't flag. Ignore obvious placeholders.\n",
    "        </instruction>\n",
    "        <schema>\n",
    "        Output exactly:\n",
    "        [\n",
    "        { \"line_number\": <int original line>, \"comment\": \"<types comma-separated>. Please remove.\" }\n",
    "        ]\n",
    "        Return [] if nothing is found. No extra text.\n",
    "        </schema>\n",
    "        <procedure>\n",
    "        1) Split CHUNK by \"\\n\".\n",
    "        2) For each line i (1-based), assess for secrets/PII using field names and context (e.g., \"api_key\", \"token\", \"password\", \"private_key\", DSN with user:pass, \"Authorization: Bearer ...\", service-account fields like private_key_id/private_key).\n",
    "        3) If flagged, compute original line_number = START + i - 1.\n",
    "        4) Emit JSON as per <schema>, comments short, no code excerpts.\n",
    "        </procedure>\n",
    "        <example>\n",
    "        INPUT:\n",
    "        START=4, END=7\n",
    "        CHUNK:\n",
    "        print(\"ok\")\n",
    "        \"private_key_id\": \"f4f3c2e1d0b9a8f7e6d5c4b3a2918171\",\n",
    "        print(\"done\")\n",
    "\n",
    "        OUTPUT:\n",
    "        [\n",
    "        { \"line_number\": 5, \"comment\": \"Private key identifier. Please remove.\" }\n",
    "        ]\n",
    "        </example>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chat_client: OpenAIChatClient,  my_shard: int, total_agents: int, id: str = \"secrets detector\"):\n",
    "        agent = chat_client.create_agent(\n",
    "            instructions=self.agent_instruction,\n",
    "            name=f\"SecretsDetectorAgent_{id}\",\n",
    "        )\n",
    "        self.id = id\n",
    "        self.agent = agent\n",
    "        self.my_shard = my_shard\n",
    "        self.total_agents = total_agents\n",
    "        super().__init__(agent=agent, id=id)\n",
    "    \n",
    "    def create_prompt_from_chunk(self, chunk: TextChunk):\n",
    "        prompt = f\"\"\"\n",
    "            Please investigate and detect secrets existent in the chunk taken from the line intervals of the file {chunk.source_file}.\n",
    "            INPUT\n",
    "            START={chunk.line_span[0]}, END={chunk.line_span[1]}\n",
    "            CHUNK:\n",
    "            {chunk.text}\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    \n",
    "    @handler\n",
    "    async def run(self, chunk: TextChunk,ctx: WorkflowContext[SecretsDetectorExecutorResponse]) -> None:\n",
    "        if shard_for_chunk(chunk, self.total_agents) != self.my_shard:\n",
    "            return\n",
    "        prompt = self.create_prompt_from_chunk(chunk)\n",
    "        key = stable_uuid(repr((chunk.source_file, chunk.line_span)))\n",
    "\n",
    "        async with ctx.shared_state.hold():\n",
    "            chunk_processed = await ctx.shared_state.get_within_hold(key)\n",
    "            if chunk_processed:\n",
    "                await ctx.send_message(EmptySecretsDetectorExecutorResponseFactory.get_empty_secrets_detector())\n",
    "                return\n",
    "            await ctx.shared_state.set_within_hold(key, True)\n",
    "        response = await self.agent.run(prompt)\n",
    "        identified_problematic_lines = [LineComment(line_number=elem[\"line_number\"], comment=elem[\"comment\"]) for elem in json.loads(response.text)]\n",
    "        await ctx.set_shared_state(key, True)\n",
    "        await ctx.send_message(SecretsDetectorExecutorResponse(comments=identified_problematic_lines, \n",
    "                                                               original_file=chunk.source_file, \n",
    "                                                               executor_agent=self.id,\n",
    "                                                               repo=chunk.repo,\n",
    "                                                               repo_owner=chunk.repo_owner,\n",
    "                                                               pull_request_number=chunk.pull_request_number\n",
    "                                                               ))\n",
    "\n",
    "\n",
    "class ChunksExporterExec(Executor):\n",
    "    def __init__(self, id):\n",
    "         self.id = id\n",
    "         super().__init__(id=id)\n",
    "    @handler\n",
    "    async def run(self, _: str,ctx: WorkflowContext[TextChunk]) -> None:\n",
    "        \"\"\"Sends input test chunks\"\"\"\n",
    "        final_results = []\n",
    "        await ctx.set_shared_state(DETECTED_SECRETS_RESULT_KEY, final_results)\n",
    "        for chunk in input_test_chunks:\n",
    "            start, end = chunk[\"original_lines_interval\"]\n",
    "            text_chunk = TextChunk(chunk=str(chunk[\"chunk\"]), \n",
    "                                             line_span=(int(start), int(end)), \n",
    "                                             source_file=str(chunk[\"original_file\"]),\n",
    "                                             repo=str(chunk[\"repo\"]),\n",
    "                                             repo_owner=str(chunk[\"repo_owner\"]),\n",
    "                                             pull_request_number=str(chunk[\"pull_request_number\"])\n",
    "                                             )\n",
    "            key = stable_uuid(repr((text_chunk.source_file, text_chunk.line_span)))\n",
    "            await ctx.set_shared_state(key, False)\n",
    "            await ctx.send_message(text_chunk)\n",
    "        \n",
    "\n",
    "class ChunksAgregatorExec(Executor):\n",
    "\n",
    "    def __init__(self, id, github_mcp_server):\n",
    "         self.id = id\n",
    "         self.github_mcp_server = github_mcp_server\n",
    "         all_tools = [*self.github_mcp_server.functions]\n",
    "         self.github_mcp_client = ChatAgent(\n",
    "                chat_client=chat_client,\n",
    "                instructions=(\n",
    "                    \"You are a helpful assistant that writes review comments on GitHub PRs. \"\n",
    "                    \"Respond with 'SUCCESS' if the operation succeeded, otherwise 'FAILURE: <reason>'.\"\n",
    "                ),\n",
    "                name=\"GithubCodeReviewerAgent\",\n",
    "                tools=all_tools,\n",
    "            )\n",
    "         super().__init__(id=id)\n",
    "\n",
    "    async def _call_github_mcp_client(self, detected_secret: SecretsDetectorExecutorResponse, line_comment: LineComment):\n",
    "        prompt = (\n",
    "            f\"Add the comment '{line_comment.comment}' to pull request \"\n",
    "            f\"#{detected_secret.pull_request_number} in repository \"\n",
    "            f\"'{detected_secret.repo_owner}/{detected_secret.repo}', \"\n",
    "            f\"file '{detected_secret.original_file}', at line {line_comment.line_number}. \"\n",
    "            f\"If there is no active review, create one.\"\n",
    "        )\n",
    "        return await self.github_mcp_client.run(prompt)\n",
    "\n",
    "    @handler\n",
    "    async def run(self, detected_secrets: list[SecretsDetectorExecutorResponse] ,ctx: WorkflowContext[None]) -> None:\n",
    "        \"\"\"Sends input test chunks\"\"\"\n",
    "        filtered_nonempty = [secret for secret in detected_secrets if not secret.is_empty()]\n",
    "        for elem in filtered_nonempty:\n",
    "            for comment in elem.comments:\n",
    "                await self._call_github_mcp_client(detected_secret=elem, line_comment=comment)\n",
    "        await ctx.add_event(CustomResponseEvent(filtered_nonempty))\n",
    "\n",
    "class ImprovedChunksAgregatorExec(Executor):\n",
    "\n",
    "    def __init__(self, id, github_mcp_server):\n",
    "         self.id = id\n",
    "         self.github_mcp_server = github_mcp_server\n",
    "         all_tools = [*self.github_mcp_server.functions]\n",
    "         self.github_mcp_client = ChatAgent(\n",
    "                chat_client=chat_client,\n",
    "                instructions=(\n",
    "                    \"You are a helpful assistant that writes review comments on GitHub PRs. \"\n",
    "                    \"Respond with 'SUCCESS' if the operation succeeded, otherwise 'FAILURE: <reason>'.\"\n",
    "                ),\n",
    "                name=\"GithubCodeReviewerAgent\",\n",
    "                tools=all_tools,\n",
    "            )\n",
    "         super().__init__(id=id)\n",
    "\n",
    "    async def _call_github_mcp_client(self, detected_secret: SecretsDetectorExecutorResponse, line_comment: LineComment):\n",
    "        prompt = (\n",
    "            f\"Add the comment '{line_comment.comment}' to pull request \"\n",
    "            f\"#{detected_secret.pull_request_number} in repository \"\n",
    "            f\"'{detected_secret.repo_owner}/{detected_secret.repo}', \"\n",
    "            f\"file '{detected_secret.original_file}', at line {line_comment.line_number}. \"\n",
    "            f\"If there is no active review, create one.\"\n",
    "        )\n",
    "        return await self.github_mcp_client.run(prompt)\n",
    "\n",
    "    async def _bounded_call(\n",
    "        self,\n",
    "        sem: asyncio.Semaphore,\n",
    "        detected_secret: SecretsDetectorExecutorResponse,\n",
    "        line_comment: LineComment,\n",
    "    ):\n",
    "        async with sem:\n",
    "            try:\n",
    "                return await self._call_github_mcp_client(detected_secret, line_comment)\n",
    "            except Exception as e:\n",
    "                # Surface failures but don’t crash the whole batch\n",
    "                return f\"FAILURE: {type(e).__name__}: {e}\"\n",
    "    \n",
    "    @handler\n",
    "    async def run(self, detected_secrets: list[SecretsDetectorExecutorResponse] ,ctx: WorkflowContext[None]) -> None:\n",
    "        \"\"\"Sends input test chunks\"\"\"\n",
    "        sem = asyncio.Semaphore(self.max_concurrency)\n",
    "        tasks: list[asyncio.Task] = []\n",
    "        filtered_nonempty = [secret for secret in detected_secrets if not secret.is_empty()]\n",
    "        for elem in filtered_nonempty:\n",
    "            for comment in elem.comments:\n",
    "                tasks.append(asyncio.create_task(self._bounded_call(sem, elem, comment)))\n",
    "\n",
    "        # Fire all at once and wait for completion\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=False)\n",
    "\n",
    "        # (Optional) summarize successes/failures if you want to emit a richer event\n",
    "        await ctx.add_event(CustomResponseEvent({\n",
    "            \"processed_items\": len(tasks),\n",
    "            \"successes\": sum(1 for r in results if isinstance(r, str) and r.startswith(\"SUCCESS\")),\n",
    "            \"failures\": [r for r in results if not (isinstance(r, str) and r.startswith(\"SUCCESS\"))],\n",
    "            \"secrets\": filtered_nonempty,\n",
    "        }))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef9adf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import MCPStdioTool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_chat_client = OpenAIChatClient(base_url=os.getenv(\"BASE_URL\"), api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN_FULL_PERMISIONS\")\n",
    "GITHUB_HOST = \"\"\n",
    "toolsets = \"repos,issues,pull_requests,actions,code_security,experiments\"\n",
    "github_mcp_server = MCPStdioTool(\n",
    "    name=\"GitHubMCP\",\n",
    "    command=\"docker\",\n",
    "    args=[\n",
    "        \"run\", \"-i\", \"--rm\",\n",
    "        \"-e\", f\"GITHUB_PERSONAL_ACCESS_TOKEN={GITHUB_TOKEN}\", f\"-e GITHUB_TOOLSETS={toolsets}\",\n",
    "        \"ghcr.io/github/github-mcp-server\"\n",
    "    ],\n",
    "    chat_client=openai_chat_client,\n",
    ")\n",
    "await github_mcp_server.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cea32faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_agents=3\n",
    "secrets_detector_1 = SecretsDetectorExec(openai_chat_client,id=\"SecretsDetector1\", my_shard=0, total_agents=total_agents)\n",
    "secrets_detector_2 = SecretsDetectorExec(openai_chat_client, id=\"SecretsDetector2\", my_shard=1, total_agents=total_agents)\n",
    "secrets_detector_3 = SecretsDetectorExec(openai_chat_client, id=\"SecretsDetector3\", my_shard=2, total_agents=total_agents)\n",
    "exporter = ChunksExporterExec(id=\"ChunkExporterAgent\")\n",
    "aggregator = ChunksAgregatorExec(id=\"ChunksAgregatorAgent\", github_mcp_server=github_mcp_server)\n",
    "builder = WorkflowBuilder()\n",
    "builder.set_start_executor(exporter)\n",
    "builder.add_fan_out_edges(exporter, [secrets_detector_1, secrets_detector_2, secrets_detector_3])\n",
    "builder.add_fan_in_edges([secrets_detector_1,\n",
    "                          secrets_detector_2,\n",
    "                          secrets_detector_3],\n",
    "                         aggregator)\n",
    "\n",
    "workflow = builder.build()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f68af43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ChunkExporterAgent\n",
      "Completed ChunkExporterAgent: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m workflow.run_stream(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mmatch\u001b[39;00m event:\n\u001b[32m      3\u001b[39m         \u001b[38;5;28;01mcase\u001b[39;00m CustomResponseEvent() \u001b[38;5;28;01mas\u001b[39;00m output:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-Op3ouSUd-py3.11/lib/python3.11/site-packages/agent_framework/_workflows/_workflow.py:405\u001b[39m, in \u001b[36mWorkflow.run_stream\u001b[39m\u001b[34m(self, message)\u001b[39m\n\u001b[32m    395\u001b[39m         executor = \u001b[38;5;28mself\u001b[39m.get_start_executor()\n\u001b[32m    396\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m executor.execute(\n\u001b[32m    397\u001b[39m             message,\n\u001b[32m    398\u001b[39m             [\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m],  \u001b[38;5;66;03m# source_executor_ids\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    402\u001b[39m             source_span_ids=\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# No source span for workflow start\u001b[39;00m\n\u001b[32m    403\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_workflow_with_tracing(\n\u001b[32m    406\u001b[39m         initial_executor_fn=initial_execution, reset_context=\u001b[38;5;28;01mTrue\u001b[39;00m, streaming=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    407\u001b[39m     ):\n\u001b[32m    408\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-Op3ouSUd-py3.11/lib/python3.11/site-packages/agent_framework/_workflows/_workflow.py:340\u001b[39m, in \u001b[36mWorkflow._run_workflow_with_tracing\u001b[39m\u001b[34m(self, initial_executor_fn, reset_context, streaming)\u001b[39m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m initial_executor_fn()\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m# All executor executions happen within workflow span\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._runner.run_until_convergence():\n\u001b[32m    341\u001b[39m     \u001b[38;5;66;03m# Track request events for final status determination\u001b[39;00m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, RequestInfoEvent):\n\u001b[32m    343\u001b[39m         saw_request = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-Op3ouSUd-py3.11/lib/python3.11/site-packages/agent_framework/_workflows/_runner.py:117\u001b[39m, in \u001b[36mRunner.run_until_convergence\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m iteration_task.done():\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    116\u001b[39m         \u001b[38;5;66;03m# Wait briefly for any new event; timeout allows progress checks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         event = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\u001b[38;5;28mself\u001b[39m._ctx.next_event(), timeout=\u001b[32m0.05\u001b[39m)\n\u001b[32m    118\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.TimeoutError:\n\u001b[32m    120\u001b[39m         \u001b[38;5;66;03m# Periodically continue to let iteration advance\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:476\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    474\u001b[39m     \u001b[38;5;66;03m# wait until the future completes or the timeout\u001b[39;00m\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError:\n\u001b[32m    478\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fut.done():\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "async for event in workflow.run_stream(\"\"):\n",
    "    match event:\n",
    "        case CustomResponseEvent() as output:\n",
    "            print(f\"Workflow finished\")\n",
    "        case ExecutorInvokedEvent() as invoke:\n",
    "            print(f\"Starting {invoke.executor_id}\")\n",
    "        case ExecutorCompletedEvent() as complete:\n",
    "            print(f\"Completed {complete.executor_id}: {complete.data}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-demo-cUoC1oNG-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
