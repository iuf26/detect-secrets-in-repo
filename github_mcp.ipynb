{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dec06a9",
   "metadata": {},
   "source": [
    "## Part 1: Experiment interaction with Gtihub MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be03678",
   "metadata": {},
   "source": [
    "#### Example: Run GitHub MCP server locally in Docker\n",
    "The following code loads environment settings, spins up an OpenAI chat client, and launches GitHub’s MCP server inside Docker so the agent can call GitHub tools.\n",
    "\n",
    "dotenv pulls in API keys and MCP settings from .env.\n",
    "OpenAIChatClient is configured with your custom base URL/model so every MCP call uses that backend.\n",
    "\n",
    "The MCP tool definition wraps docker run; it injects the GitHub PAT plus the list of toolsets the server should expose.\n",
    "await github_mcp.connect() starts the Docker container and establishes the socket so subsequent ChatAgent runs can invoke GitHub functions (repos, PRs, issues, etc.) through the MCP layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c5bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub MCP connected\n"
     ]
    }
   ],
   "source": [
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import MCPStdioTool, ChatAgent\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "chat_client = OpenAIChatClient(api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN_FULL_PERMISIONS\")\n",
    "GITHUB_HOST = \"\"\n",
    "toolsets = \"repos,issues,pull_requests,actions,code_security,experiments\"\n",
    "github_mcp = MCPStdioTool(\n",
    "    name=\"GitHubMCP\",\n",
    "    command=\"docker\",\n",
    "    args=[\n",
    "        \"run\", \"-i\", \"--rm\",\n",
    "        \"-e\", f\"GITHUB_PERSONAL_ACCESS_TOKEN={GITHUB_TOKEN}\", f\"-e GITHUB_TOOLSETS={toolsets}\",\n",
    "        \"ghcr.io/github/github-mcp-server\"\n",
    "    ],\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "await github_mcp.connect()\n",
    "print(\"GitHub MCP connected\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71486542",
   "metadata": {},
   "source": [
    "### Example: Write comment to a pull request using Github's MCP server\n",
    "\n",
    "This block wires the GitHub MCP tools into a task‑specific agent that leaves a review comment on a pull request.\n",
    "\n",
    "all_tools = [*github_mcp.functions] expands every capability exposed by the connected MCP server (issues, PR reviews, etc.).\n",
    "\n",
    "The instructions string plays system prompt: the agent must operate only on iuf26/workshop-project-detect-secrets-in-repo and reply with SUCCESS or FAILURE.\n",
    "\n",
    "ChatAgent binds those instructions, the shared chat_client, and the MCP tool list into a named agent (ResearchAgent).\n",
    "\n",
    "The await agent.run(...) call triggers one conversational turn where the agent visits PR #1, starts a review if needed, and posts the requested comment on leaky_sample.py line 6; the printed result is just SUCCESS or FAILURE + reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1644b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "all_tools = [*github_mcp.functions]\n",
    "instructions = \"\"\"\n",
    "You are a helpful assistant that helps me write comments to the 'workshop-detect_secrets' github repository with OWNER 'flaviusfetean'. \n",
    "As a response only return 'SUCCESS' if operation succeeded and otherwise return 'FAILURE' and reason for failure.\n",
    "If you get errors while attempting to write the comment, please attempt first to work around it (unless there is no way to do so).\n",
    "\"\"\"\n",
    "agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"ResearchAgent\",\n",
    "    tools=all_tools\n",
    " )\n",
    "result = await agent.run(\"I would like to add the 'please remove this secret number 12 9 November' comment to the pull request number 1 to the 'leaky_sample.py' file at line number 12. If there is no review started for the viewer please do create it.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1ccf7",
   "metadata": {},
   "source": [
    "### Example: Retrieve all files from a PR using GitHub MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a848f7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/flaviusfetean/workshop-detect_secrets/blob/feat/add_secrets/leaky_sample.py\n"
     ]
    }
   ],
   "source": [
    "from domain.models import PRFileList\n",
    "all_tools = [*github_mcp.functions]\n",
    "instructions = \"\"\"\n",
    "You are a helpful assistant. Retrieve all files included in an open pull request from the GitHub repository 'flaviusfetean/workshop-detect_secrets'.\n",
    "Respond only with a list of direct links (URLs) to the files changed or added in the pull request — no explanations or additional text.\n",
    "\"\"\"\n",
    "github_pr_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"PullRequestAgent\",\n",
    "    tools=all_tools\n",
    " )\n",
    "result = await github_pr_agent.run(\"Get me all the files involved in the PR with number 1.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28919e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured result: files=[PRFileInfo(source_file='leaky_sample.py', pull_request_number='1', source_branch='feat/add_secrets', repo='workshop-detect_secrets', repo_owner='flaviusfetean')]\n"
     ]
    }
   ],
   "source": [
    "from domain.models import PRFileList, PRFileInfo\n",
    "instructions = \"\"\"\n",
    "You are a helpful assistant. Retrieve all files included in the open pull request from the GitHub repository 'flaviusfetean/workshop-detect_secrets'.\n",
    "\"\"\"\n",
    "github_pr_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=instructions,\n",
    "    name=\"PullRequestAgent\",\n",
    "    tools=all_tools, \n",
    "    response_format=PRFileList\n",
    " )\n",
    "# Extract with structured output\n",
    "result_structured = await github_pr_agent.run(\n",
    "    \"Get me all the files involved in the PR with number 1.\",\n",
    "    response_model=PRFileList\n",
    ")\n",
    "print(\"Structured result:\", result_structured.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef2837",
   "metadata": {},
   "source": [
    "### Example: List all github mcp server tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a833801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_comment_to_pending_review\n",
      "add_issue_comment\n",
      "assign_copilot_to_issue\n",
      "create_branch\n",
      "create_or_update_file\n",
      "create_pull_request\n",
      "create_repository\n",
      "delete_file\n",
      "fork_repository\n",
      "get_commit\n",
      "get_file_contents\n",
      "get_label\n",
      "get_latest_release\n",
      "get_me\n",
      "get_release_by_tag\n",
      "get_tag\n",
      "get_team_members\n",
      "get_teams\n",
      "issue_read\n",
      "issue_write\n",
      "list_branches\n",
      "list_commits\n",
      "list_issue_types\n",
      "list_issues\n",
      "list_pull_requests\n",
      "list_releases\n",
      "list_tags\n",
      "merge_pull_request\n",
      "pull_request_read\n",
      "pull_request_review_write\n",
      "push_files\n",
      "request_copilot_review\n",
      "search_code\n",
      "search_issues\n",
      "search_pull_requests\n",
      "search_repositories\n",
      "search_users\n",
      "sub_issue_write\n",
      "update_pull_request\n",
      "update_pull_request_branch\n",
      "AssignCodingAgent\n",
      "IssueToFixWorkflow\n"
     ]
    }
   ],
   "source": [
    "for elem in github_mcp.functions:\n",
    "    print(elem.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74eac9",
   "metadata": {},
   "source": [
    "## Part 2: Implement agentic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb5990",
   "metadata": {},
   "source": [
    "### Define Chunk processing research agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f168d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_chunks = [\n",
    "  {\n",
    "    \"chunk\": \"import os\\nDEBUG=True\\nDATABASE_URL=\\\"postgresql://appuser:Sup3rS3cret!@db:5432/app\\\"\\nJWT_SECRET=\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.fake.payload\\\"\\nADMIN_EMAIL=\\\"maria.popescu@example.ro\\\"\\nADMIN_PHONE=\\\"+40-721-555-321\\\"\\nSMTP_PASSWORD=\\\"p@55w0rd!\\\"\\nLOG_LEVEL=\\\"INFO\\\"\\nprint(\\\"config loaded\\\")\",\n",
    "    \"original_lines_interval\": [120, 128],\n",
    "    \"original_file\": \"src/app/config.py\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"# .env\\nAWS_ACCESS_KEY_ID=AKIAZZZZEXAMPLE1234\\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYZZZexample\\nS3_BUCKET=media-prod\\nSTRIPE_WEBHOOK_SECRET=whsec_1e2b3c4d5e6f7g8h9i0j\\nREDIS_URL=redis://:s3cr3tP@redis:6379/0\\n# service creds\\nSERVICE_EMAIL=ops.team@example.com\\nSERVICE_PHONE=+40-745-000-111\\nNODE_ENV=production\",\n",
    "    \"original_lines_interval\": [45, 52],\n",
    "    \"original_file\": \"services/api/.env\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"// config.js\\nmodule.exports = {\\n  stripeKey: \\\"sk_live_51NvEXAMPLEaBcD1234567890\\\",\\n  headers: {\\n    \\\"Authorization\\\": \\\"Bearer eyJraWQiOiJrZXkiLCJhbGciOiJIUzI1NiJ9.fake.token\\\",\\n    \\\"X-Api-Key\\\": \\\"b7b2f0c6-1b24-4e1a-9c1a-12e34abcd567\\\"\\n  },\\n  supportEmail: \\\"support@example.com\\\",\\n  logLevel: \\\"debug\\\"\\n};\",\n",
    "    \"original_lines_interval\": [200, 209],\n",
    "    \"original_file\": \"web/src/config.js\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"apiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: app-config\\ndata:\\n  DB_DSN: \\\"mysql://admin:hunter2@mysql:3306/app\\\"\\n  MAIL_USER: \\\"mailer@example.ro\\\"\\n  MAIL_PASS: \\\"Tr1cky-P@ss!\\\"\\n  OAUTH_CLIENT_SECRET: \\\"c0a89e5f-7d1f-4d0c-9b77-1a2b3c4d5e6f\\\"\",\n",
    "    \"original_lines_interval\": [31, 41],\n",
    "    \"original_file\": \"deploy/k8s/app-config.yaml\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"{\\n  \\\"type\\\": \\\"service_account\\\",\\n  \\\"project_id\\\": \\\"demo-proj-123\\\",\\n  \\\"private_key_id\\\": \\\"f4f3c2e1d0b9a8f7e6d5c4b3a2918171\\\",\\n  \\\"private_key\\\": \\\"-----BEGIN PRIVATE KEY-----\\\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBK...FAKE...\\\\n-----END PRIVATE KEY-----\\\\n\\\",\\n  \\\"client_email\\\": \\\"svc-acc@demo-proj-123.iam.gserviceaccount.com\\\",\\n  \\\"client_id\\\": \\\"109876543210987654321\\\",\\n  \\\"auth_uri\\\": \\\"https://accounts.google.com/o/oauth2/auth\\\"\\n}\",\n",
    "    \"original_lines_interval\": [402, 410],\n",
    "    \"original_file\": \"infra/gcp/service-account.json\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"#!/usr/bin/env bash\\nexport GITHUB_TOKEN=ghp_FAKE1234567890abcdef1234567890abcd\\nexport SLACK_BOT_TOKEN=xoxb-123456789012-1234567890123-ABCdefGHIjklMNOpqr\\ncurl -s -H \\\"Authorization: Bearer $GITHUB_TOKEN\\\" https://api.github.com/user\\ncurl -u \\\"deployer:Sup3r-Secret!\\\" https://registry.example.com/v2/_catalog\\nEMAIL_NOTIFY=\\\"andrei.ionescu@example.com\\\"\\necho \\\"Done\\\"\",\n",
    "    \"original_lines_interval\": [88, 96],\n",
    "    \"original_file\": \"scripts/release.sh\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"-- seed.sql\\nINSERT INTO users (full_name, email, phone, password_plain)\\nVALUES ('Ioana Radu','ioana.radu@example.ro','+40 722 111 222','summer2025');\\nINSERT INTO api_credentials (name, token)\\nVALUES ('internal-bot','eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.fake');\\n-- DO NOT COMMIT REAL DATA\",\n",
    "    \"original_lines_interval\": [12, 16],\n",
    "    \"original_file\": \"db/seed.sql\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"variable \\\"cloud_api_token\\\" {\\n  type = string\\n  default = \\\"tkn_live_3b2f1c4d5e6f7a8b9c0d\\\"\\n}\\nprovider \\\"example\\\" {\\n  token = var.cloud_api_token\\n}\\noutput \\\"endpoint\\\" { value = example_service.url }\",\n",
    "    \"original_lines_interval\": [77, 84],\n",
    "    \"original_file\": \"infra/terraform/vars.tf\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"spring.datasource.url=jdbc:postgresql://db:5432/app?user=app&password=Str0ngP@ss\\nspring.mail.username=mailer@example.ro\\nspring.mail.password=Qwerty!234\\njwt.signing.key=5a6b7c8d9e0f11223344556677889900\\nmanagement.endpoints.web.exposure.include=health,info,metrics\\nsupport.phone=+40-733-000-222\",\n",
    "    \"original_lines_interval\": [15, 20],\n",
    "    \"original_file\": \"service/src/main/resources/application-prod.properties\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"chunk\": \"# notebook cell\\nOPENAI_API_KEY=\\\"sk-live-abc123XYZ987fakefakefake\\\"\\nTWILIO_ACCOUNT_SID=\\\"AC1234567890abcdef1234567890abcd\\\"\\nTWILIO_AUTH_TOKEN=\\\"9d8c7b6a5e4f3d2c1b0a\\\"\\nuser_name = \\\"Ciprian Istrate\\\"\\nuser_email = \\\"ciprian.istrate@example.com\\\"\\nprint(\\\"init done\\\")\",\n",
    "    \"original_lines_interval\": [260, 266],\n",
    "    \"original_file\": \"notebooks/exp01.ipynb\",\n",
    "    \"pull_request_number\": \"\",\n",
    "    \"repo\": \"\",\n",
    "    \"repo_owner\": \"\"\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df6b45",
   "metadata": {},
   "source": [
    "### Test split chunk\n",
    "Split sample file that is found in the PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9244b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import code\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "def split_file_by_newlines(\n",
    "    file_path: str,\n",
    "    newlines_per_chunk: int,\n",
    "    pull_request_number: str = \"\",\n",
    "    repo: str = \"\",\n",
    "    repo_owner: str = \"\",\n",
    ") -> List[Dict]:\n",
    "    \"\"\" \n",
    "    Split a text file into chunks containing a fixed number of newline separators.\n",
    "    - Normalizes all line endings to '\\n' first.\n",
    "    - `original_lines_interval` is 1-based and inclusive.\n",
    "    - If the last chunk has fewer lines (fewer '\\n' separators), it's still included.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"http\" in file_path:\n",
    "        import requests\n",
    "\n",
    "        filepath_github_raw = file_path.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
    "\n",
    "        r = requests.get(filepath_github_raw)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        text = r.text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "        original_file = file_path.split(\"/\")[-1]\n",
    "        print(text[:200])  # print first 200 chars\n",
    "    else:\n",
    "        p = Path(file_path)\n",
    "        original_file = p.name\n",
    "\n",
    "        # Normalize all newlines to '\\n' to ensure consistent splitting\n",
    "        text = p.read_text(encoding=\"utf-8\", errors=\"replace\").replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # Split strictly by '\\n'\n",
    "    lines = text.split(\"\\n\")  # newline characters are removed by split\n",
    "    total_lines = len(lines)\n",
    "\n",
    "    chunks: List[Dict] = []\n",
    "\n",
    "    # Step through in blocks of `newlines_per_chunk` lines\n",
    "    for i in range(0, total_lines, newlines_per_chunk):\n",
    "        block = lines[i : i + newlines_per_chunk]\n",
    "        if not block:\n",
    "            continue\n",
    "\n",
    "        # Reconstruct the chunk string with '\\n' between lines.\n",
    "        # IMPORTANT: we DO NOT append a trailing '\\n' at the end of the chunk.\n",
    "        chunk_text = \"\\n\".join(block)\n",
    "\n",
    "        # 1-based line numbers for the original interval\n",
    "        start_line = i + 1\n",
    "        end_line = i + len(block)\n",
    "\n",
    "        chunks.append({\n",
    "            \"chunk\": chunk_text,\n",
    "            \"original_lines_interval\": [start_line, end_line],\n",
    "            \"original_file\": original_file,\n",
    "            \"pull_request_number\": pull_request_number,\n",
    "            \"repo\": repo,\n",
    "            \"repo_owner\": repo_owner,\n",
    "        })\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522e7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_chunks = split_file_by_newlines(\"samples/leaky_sample.py\",10,\"1\",repo=\"workshop-detect-secrets-in-repo\",repo_owner=\"iuf26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5569bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# leaky_sample.py\n",
      "# ⚠️ FAKE CREDENTIALS FOR TESTING ONLY. NONE OF THESE WORK.\n",
      "# This file intentionally contains strings that *look like* secrets so you can\n",
      "# test detectors, LLMs, and CI scanners. Do\n"
     ]
    }
   ],
   "source": [
    "input_test_chunks_from_url = split_file_by_newlines(\"https://raw.githubusercontent.com/flaviusfetean/workshop-detect_secrets/feat/add_secrets/leaky_sample.py\",10,\"1\",repo=\"workshop-detect_secrets\",repo_owner=\"flaviusfetean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b844cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "from domain.models import TextChunk\n",
    "\n",
    "NAMESPACE = uuid.UUID(\"876de125-4386-442b-9e88-d40dfbbb301d\")  # pick once & keep\n",
    "def stable_uuid(s: str) -> str:\n",
    "    s = s.strip().lower()  # normalize to avoid accidental mismatches\n",
    "    return str(uuid.uuid5(NAMESPACE, s))\n",
    "\n",
    "def shard_for_chunk(chunk: TextChunk, total_agents: int) -> int:\n",
    "    \"\"\"\n",
    "    Pick which worker (0..total_agents-1) should handle this chunk.\n",
    "\n",
    "    How it works (in plain words):\n",
    "    - Build a key from the file name and line range (e.g., \"app.py|120|180\").\n",
    "    - Hash that key with SHA-256 (gives a big, stable number).\n",
    "    - Take that number modulo total_agents to get a shard index.\n",
    "\n",
    "    Inputs:\n",
    "    - chunk: has `source_file: str` and `line_span: (start:int, end:int)`.\n",
    "    - total_agents: number of workers; must be >= 1.\n",
    "\n",
    "    Guarantees:\n",
    "    - Same chunk → same shard index (deterministic).\n",
    "    - Result r is an int with 0 <= r < total_agents.\n",
    "\n",
    "    Example:\n",
    "    >> shard_for_chunk(TextChunk(source_file=\"a.py\", line_span=(10, 30)), total_agents=3)\n",
    "    2\n",
    "    \"\"\"\n",
    "    h = hashlib.sha256(f\"{chunk.source_file}|{chunk.line_span}\".encode()).digest()\n",
    "    return int.from_bytes(h[:4], \"big\") % total_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agent_framework import Executor, WorkflowBuilder, WorkflowEvent, handler, WorkflowContext, ChatAgent, ExecutorInvokedEvent, ExecutorCompletedEvent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "import json\n",
    "from domain.models import TextChunk, LineComment, SecretsDetectorExecutorResponse, EmptySecretsDetectorExecutorResponseFactory, PRFileList, PRFileInfo\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "chat_client = OpenAIChatClient(base_url=os.getenv(\"BASE_URL\"), api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_PAT\")\n",
    "DETECTED_SECRETS_RESULT_KEY = \"detected_secrets\"\n",
    "\n",
    "class CustomResponseEvent(WorkflowEvent):\n",
    "    def __init__(self, result: list[SecretsDetectorExecutorResponse]):\n",
    "        super().__init__(result)\n",
    "\n",
    "class SecretsDetectorExec(Executor):\n",
    "    agent: ChatAgent\n",
    "    agent_instruction = \"\"\"\n",
    "        <instruction role=\"system\">\n",
    "        You are a code-secrets detector. Given a text CHUNK (with \"\\n\" newlines) and its original line interval [START, END], return only a JSON array of findings. Flag lines that contain likely secrets (API keys/tokens, private keys, passwords, connection strings with creds, service-account JSON fields, auth headers) or PII (names paired with email/phone/IDs). Be precise; if unsure, don't flag. Ignore obvious placeholders.\n",
    "        </instruction>\n",
    "        <schema>\n",
    "        Output exactly:\n",
    "        [\n",
    "        { \"line_number\": <int original line>, \"comment\": \"<types comma-separated>. Please remove.\" }\n",
    "        ]\n",
    "        Return [] if nothing is found. No extra text.\n",
    "        </schema>\n",
    "        <procedure>\n",
    "        1) Split CHUNK by \"\\n\".\n",
    "        2) For each line i (1-based), assess for secrets/PII using field names and context (e.g., \"api_key\", \"token\", \"password\", \"private_key\", DSN with user:pass, \"Authorization: Bearer ...\", service-account fields like private_key_id/private_key).\n",
    "        3) If flagged, compute original line_number = START + i - 1.\n",
    "        4) Emit JSON as per <schema>, comments short, no code excerpts.\n",
    "        </procedure>\n",
    "        <example>\n",
    "        INPUT:\n",
    "        START=4, END=7\n",
    "        CHUNK:\n",
    "        print(\"ok\")\n",
    "        \"private_key_id\": \"f4f3c2e1d0b9a8f7e6d5c4b3a2918171\",\n",
    "        print(\"done\")\n",
    "\n",
    "        OUTPUT:\n",
    "        [\n",
    "        { \"line_number\": 5, \"comment\": \"Private key identifier. Please remove.\" }\n",
    "        ]\n",
    "        </example>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chat_client: OpenAIChatClient,  my_shard: int, total_agents: int, id: str = \"secrets detector\"):\n",
    "        agent = chat_client.create_agent(\n",
    "            instructions=self.agent_instruction,\n",
    "            name=f\"SecretsDetectorAgent_{id}\",\n",
    "        )\n",
    "        self.id = id\n",
    "        self.agent = agent\n",
    "        self.my_shard = my_shard\n",
    "        self.total_agents = total_agents\n",
    "        super().__init__(agent=agent, id=id)\n",
    "    \n",
    "    def create_prompt_from_chunk(self, chunk: TextChunk):\n",
    "        prompt = f\"\"\"\n",
    "            Please investigate and detect secrets existent in the chunk taken from the line intervals of the file {chunk.source_file}.\n",
    "            INPUT\n",
    "            START={chunk.line_span[0]}, END={chunk.line_span[1]}\n",
    "            CHUNK:\n",
    "            {chunk.text}\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    \n",
    "    @handler\n",
    "    async def run(self, chunk: TextChunk,ctx: WorkflowContext[SecretsDetectorExecutorResponse]) -> None:\n",
    "        if shard_for_chunk(chunk, self.total_agents) != self.my_shard:\n",
    "            return\n",
    "        prompt = self.create_prompt_from_chunk(chunk)\n",
    "        key = stable_uuid(repr((chunk.source_file, chunk.line_span)))\n",
    "\n",
    "        async with ctx.shared_state.hold():\n",
    "            chunk_processed = await ctx.shared_state.get_within_hold(key)\n",
    "            if chunk_processed:\n",
    "                await ctx.send_message(EmptySecretsDetectorExecutorResponseFactory.get_empty_secrets_detector())\n",
    "                return\n",
    "            await ctx.shared_state.set_within_hold(key, True)\n",
    "        response = await self.agent.run(prompt)\n",
    "        identified_problematic_lines = [LineComment(line_number=elem[\"line_number\"], comment=elem[\"comment\"]) for elem in json.loads(response.text)]\n",
    "        await ctx.set_shared_state(key, True)\n",
    "        await ctx.send_message(SecretsDetectorExecutorResponse(comments=identified_problematic_lines, \n",
    "                                                               original_file=chunk.source_file, \n",
    "                                                               executor_agent=self.id,\n",
    "                                                               repo=chunk.repo,\n",
    "                                                               repo_owner=chunk.repo_owner,\n",
    "                                                               pull_request_number=chunk.pull_request_number\n",
    "                                                               ))\n",
    "\n",
    "\n",
    "class ChunksExporterExec(Executor):\n",
    "    def __init__(self, id):\n",
    "         self.id = id\n",
    "         super().__init__(id=id)\n",
    "\n",
    "    @handler\n",
    "    async def run(self, _: str,ctx: WorkflowContext[TextChunk]) -> None:\n",
    "        \"\"\"Sends input test chunks\"\"\"\n",
    "        final_results = []\n",
    "        await ctx.set_shared_state(DETECTED_SECRETS_RESULT_KEY, final_results)\n",
    "\n",
    "        agent_instructions = \"\"\"\n",
    "        You are a helpful assistant. Retrieve all files included in an open pull request from the GitHub repository 'flaviusfetean/workshop-detect_secrets'.\n",
    "        Respond only with a list of direct links (URLs) to the files changed or added in the pull request along with the necessary extra information (owner, repo, branch).\n",
    "        \"\"\"\n",
    "\n",
    "        files: List[PRFileInfo] = []\n",
    "        while not files:\n",
    "            github_pr_extraction_agent = ChatAgent(\n",
    "                chat_client=chat_client,\n",
    "                instructions=agent_instructions,\n",
    "                name=\"PullRequestExtractorAgent\",\n",
    "                tools=all_tools, \n",
    "                response_format=PRFileList\n",
    "            )\n",
    "\n",
    "            pr_files_response = await github_pr_extraction_agent.run(\n",
    "                \"Get me all the files involved in the PR with number 1.\",\n",
    "                response_format=PRFileList\n",
    "            )\n",
    "\n",
    "            files: List[PRFileInfo] = pr_files_response.value.files\n",
    "            if not files:\n",
    "                print(\"No files extracted, retrying...\")\n",
    "                continue\n",
    "            for file in files:\n",
    "                # Sometimes the agent outputs the full URL, we need only the filename and we build the URL ourselves\n",
    "                file.source_file = file.source_file.split(\"/\")[-1]\n",
    "            print(f\"Files in PR: {[file.source_file for file in files]}\")\n",
    "\n",
    "        input_chunks = []\n",
    "        for file in files:\n",
    "            try:\n",
    "                chunks = split_file_by_newlines(\n",
    "                    file_path=f\"https://raw.githubusercontent.com/{file.repo_owner}/{file.repo}/{file.source_branch}/{file.source_file}\",\n",
    "                    newlines_per_chunk=10,\n",
    "                    pull_request_number=file.pull_request_number,\n",
    "                    repo=file.repo,\n",
    "                    repo_owner=file.repo_owner\n",
    "                )\n",
    "                input_chunks.extend(chunks)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file.source_file}: {e}\")\n",
    "\n",
    "        for chunk in input_chunks:\n",
    "            start, end = chunk[\"original_lines_interval\"]\n",
    "            text_chunk = TextChunk(chunk=str(chunk[\"chunk\"]), \n",
    "                                             line_span=(int(start), int(end)), \n",
    "                                             source_file=str(chunk[\"original_file\"]),\n",
    "                                             repo=str(chunk[\"repo\"]),\n",
    "                                             repo_owner=str(chunk[\"repo_owner\"]),\n",
    "                                             pull_request_number=str(chunk[\"pull_request_number\"])\n",
    "                                             )\n",
    "            key = stable_uuid(repr((text_chunk.source_file, text_chunk.line_span)))\n",
    "            await ctx.set_shared_state(key, False)\n",
    "            await ctx.send_message(text_chunk)\n",
    "        \n",
    "\n",
    "class ChunksAgregatorExec(Executor):\n",
    "\n",
    "    def __init__(self, id, github_mcp_server):\n",
    "         self.id = id\n",
    "         self.github_mcp_server = github_mcp_server\n",
    "         all_tools = [*self.github_mcp_server.functions]\n",
    "         self.github_mcp_client = ChatAgent(\n",
    "                chat_client=chat_client,\n",
    "                instructions=(\n",
    "                    \"You are a helpful assistant that writes review comments on GitHub PRs. \"\n",
    "                    \"Respond with 'SUCCESS' if the operation succeeded, otherwise 'FAILURE: <reason>'.\"\n",
    "                ),\n",
    "                name=\"GithubCodeReviewerAgent\",\n",
    "                tools=all_tools,\n",
    "            )\n",
    "         super().__init__(id=id)\n",
    "\n",
    "    async def _call_github_mcp_client(self, detected_secret: SecretsDetectorExecutorResponse, line_comment: LineComment):\n",
    "        prompt = (\n",
    "            f\"Add the comment '{line_comment.comment}' to pull request \"\n",
    "            f\"#{detected_secret.pull_request_number} in repository \"\n",
    "            f\"'{detected_secret.repo_owner}/{detected_secret.repo}', \"\n",
    "            f\"file '{detected_secret.original_file}', at line {line_comment.line_number}. \"\n",
    "            f\"MAKE SURE TO INCLUDE THE LINE NUMBER IN THE REQUEST.\"\n",
    "            f\"If there is no active review, create one.\"\n",
    "        )\n",
    "        return await self.github_mcp_client.run(prompt)\n",
    "\n",
    "    @handler\n",
    "    async def run(self, detected_secrets: list[SecretsDetectorExecutorResponse] ,ctx: WorkflowContext[None]) -> None:\n",
    "        \"\"\"Sends input test chunks\"\"\"\n",
    "        filtered_nonempty = [secret for secret in detected_secrets if not secret.is_empty()]\n",
    "        for elem in filtered_nonempty:\n",
    "            for comment in elem.comments:\n",
    "                await self._call_github_mcp_client(detected_secret=elem, line_comment=comment)\n",
    "        await ctx.add_event(CustomResponseEvent(filtered_nonempty))\n",
    "\n",
    "class ImprovedChunksAgregatorExec(Executor):\n",
    "\n",
    "    def __init__(self, id, github_mcp_server):\n",
    "         self.id = id\n",
    "         self.github_mcp_server = github_mcp_server\n",
    "         all_tools = [*self.github_mcp_server.functions]\n",
    "         self.github_mcp_client = ChatAgent(\n",
    "                chat_client=chat_client,\n",
    "                instructions=(\n",
    "                    \"You are a helpful assistant that writes review comments on GitHub PRs. \"\n",
    "                    \"Respond with 'SUCCESS' if the operation succeeded, otherwise 'FAILURE: <reason>'.\"\n",
    "                ),\n",
    "                name=\"GithubCodeReviewerAgent\",\n",
    "                tools=all_tools,\n",
    "            )\n",
    "         super().__init__(id=id)\n",
    "\n",
    "    async def _call_github_mcp_client(self, detected_secret: SecretsDetectorExecutorResponse, line_comment: LineComment):\n",
    "        prompt = (\n",
    "            f\"Add the comment '{line_comment.comment}' to pull request \"\n",
    "            f\"#{detected_secret.pull_request_number} in repository \"\n",
    "            f\"'{detected_secret.repo_owner}/{detected_secret.repo}', \"\n",
    "            f\"file '{detected_secret.original_file}', at line {line_comment.line_number}. \"\n",
    "            f\"If there is no active review, create one.\"\n",
    "        )\n",
    "        print(f\"Adding comment for file '{detected_secret.original_file}' at line {line_comment.line_number}\")\n",
    "\n",
    "        return await self.github_mcp_client.run(prompt)\n",
    "\n",
    "    async def _bounded_call(\n",
    "        self,\n",
    "        sem: asyncio.Semaphore,\n",
    "        detected_secret: SecretsDetectorExecutorResponse,\n",
    "        line_comment: LineComment,\n",
    "    ):\n",
    "        async with sem:\n",
    "            try:\n",
    "                return await self._call_github_mcp_client(detected_secret, line_comment)\n",
    "            except Exception as e:\n",
    "                # Surface failures but don’t crash the whole batch\n",
    "                return f\"FAILURE: {type(e).__name__}: {e}\"\n",
    "    \n",
    "    @handler\n",
    "    async def run(self, detected_secrets: list[SecretsDetectorExecutorResponse] ,ctx: WorkflowContext[None]) -> None:\n",
    "        \"\"\"Sends input test chunks\"\"\"\n",
    "        sem = asyncio.Semaphore(self.max_concurrency)\n",
    "        tasks: list[asyncio.Task] = []\n",
    "        filtered_nonempty = [secret for secret in detected_secrets if not secret.is_empty()]\n",
    "        for elem in filtered_nonempty:\n",
    "            for comment in elem.comments:\n",
    "                tasks.append(asyncio.create_task(self._bounded_call(sem, elem, comment)))\n",
    "\n",
    "        # Fire all at once and wait for completion\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=False)\n",
    "\n",
    "        # (Optional) summarize successes/failures if you want to emit a richer event\n",
    "        await ctx.add_event(CustomResponseEvent({\n",
    "            \"processed_items\": len(tasks),\n",
    "            \"successes\": sum(1 for r in results if isinstance(r, str) and r.startswith(\"SUCCESS\")),\n",
    "            \"failures\": [r for r in results if not (isinstance(r, str) and r.startswith(\"SUCCESS\"))],\n",
    "            \"secrets\": filtered_nonempty,\n",
    "        }))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9adf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import MCPStdioTool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_chat_client = OpenAIChatClient(base_url=os.getenv(\"BASE_URL\"), api_key=os.getenv(\"OPENAI_API_KEY\"), model_id=os.getenv(\"MODEL_ID\"))\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN_FULL_PERMISIONS\")\n",
    "GITHUB_HOST = \"\"\n",
    "toolsets = \"repos,issues,pull_requests,actions,code_security,experiments\"\n",
    "github_mcp_server = MCPStdioTool(\n",
    "    name=\"GitHubMCP\",\n",
    "    command=\"docker\",\n",
    "    args=[\n",
    "        \"run\", \"-i\", \"--rm\",\n",
    "        \"-e\", f\"GITHUB_PERSONAL_ACCESS_TOKEN={GITHUB_TOKEN}\", f\"-e GITHUB_TOOLSETS={toolsets}\",\n",
    "        \"ghcr.io/github/github-mcp-server\"\n",
    "    ],\n",
    "    chat_client=openai_chat_client,\n",
    ")\n",
    "await github_mcp_server.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea32faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_agents=3\n",
    "secrets_detector_1 = SecretsDetectorExec(openai_chat_client,id=\"SecretsDetector1\", my_shard=0, total_agents=total_agents)\n",
    "secrets_detector_2 = SecretsDetectorExec(openai_chat_client, id=\"SecretsDetector2\", my_shard=1, total_agents=total_agents)\n",
    "secrets_detector_3 = SecretsDetectorExec(openai_chat_client, id=\"SecretsDetector3\", my_shard=2, total_agents=total_agents)\n",
    "exporter = ChunksExporterExec(id=\"ChunkExporterAgent\")\n",
    "aggregator = ChunksAgregatorExec(id=\"ChunksAgregatorAgent\", github_mcp_server=github_mcp_server)\n",
    "builder = WorkflowBuilder()\n",
    "builder.set_start_executor(exporter)\n",
    "builder.add_fan_out_edges(exporter, [secrets_detector_1, secrets_detector_2, secrets_detector_3])\n",
    "builder.add_fan_in_edges([secrets_detector_1,\n",
    "                          secrets_detector_2,\n",
    "                          secrets_detector_3],\n",
    "                         aggregator)\n",
    "\n",
    "workflow = builder.build()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68af43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in PR: ['leaky_sample.py']\n",
      "# leaky_sample.py\n",
      "# ⚠️ FAKE CREDENTIALS FOR TESTING ONLY. NONE OF THESE WORK.\n",
      "# This file intentionally contains strings that *look like* secrets so you can\n",
      "# test detectors, LLMs, and CI scanners. Do\n",
      "Starting ChunkExporterAgent\n",
      "Completed ChunkExporterAgent: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector1\n",
      "Completed SecretsDetector1: None\n",
      "Starting SecretsDetector2\n",
      "Completed SecretsDetector2: None\n",
      "Starting SecretsDetector3\n",
      "Completed SecretsDetector3: None\n",
      "Starting ChunksAgregatorAgent\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ImprovedChunksAgregatorExec' object has no attribute 'max_concurrency'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m workflow.run_stream(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mmatch\u001b[39;00m event:\n\u001b[32m      3\u001b[39m         \u001b[38;5;28;01mcase\u001b[39;00m CustomResponseEvent() \u001b[38;5;28;01mas\u001b[39;00m output:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_workflow.py:405\u001b[39m, in \u001b[36mWorkflow.run_stream\u001b[39m\u001b[34m(self, message)\u001b[39m\n\u001b[32m    395\u001b[39m         executor = \u001b[38;5;28mself\u001b[39m.get_start_executor()\n\u001b[32m    396\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m executor.execute(\n\u001b[32m    397\u001b[39m             message,\n\u001b[32m    398\u001b[39m             [\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m],  \u001b[38;5;66;03m# source_executor_ids\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    402\u001b[39m             source_span_ids=\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# No source span for workflow start\u001b[39;00m\n\u001b[32m    403\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_workflow_with_tracing(\n\u001b[32m    406\u001b[39m         initial_executor_fn=initial_execution, reset_context=\u001b[38;5;28;01mTrue\u001b[39;00m, streaming=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    407\u001b[39m     ):\n\u001b[32m    408\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_workflow.py:340\u001b[39m, in \u001b[36mWorkflow._run_workflow_with_tracing\u001b[39m\u001b[34m(self, initial_executor_fn, reset_context, streaming)\u001b[39m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m initial_executor_fn()\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m# All executor executions happen within workflow span\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._runner.run_until_convergence():\n\u001b[32m    341\u001b[39m     \u001b[38;5;66;03m# Track request events for final status determination\u001b[39;00m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, RequestInfoEvent):\n\u001b[32m    343\u001b[39m         saw_request = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_runner.py:125\u001b[39m, in \u001b[36mRunner.run_until_convergence\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Propagate errors from iteration, but first surface any pending events\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m iteration_task\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# Make sure failure-related events (like ExecutorFailedEvent) are surfaced\u001b[39;00m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ctx.has_events():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_runner.py:190\u001b[39m, in \u001b[36mRunner._run_iteration\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    188\u001b[39m messages = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ctx.drain_messages()\n\u001b[32m    189\u001b[39m tasks = [_deliver_messages(source_executor_id, messages) \u001b[38;5;28;01mfor\u001b[39;00m source_executor_id, messages \u001b[38;5;129;01min\u001b[39;00m messages.items()]\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_runner.py:186\u001b[39m, in \u001b[36mRunner._run_iteration.<locals>._deliver_messages\u001b[39m\u001b[34m(source_executor_id, messages)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Deliver a message through all edge runners associated with the source executor concurrently.\u001b[39;00m\n\u001b[32m    185\u001b[39m tasks = [_deliver_message_inner(edge_runner, message) \u001b[38;5;28;01mfor\u001b[39;00m edge_runner \u001b[38;5;129;01min\u001b[39;00m associated_edge_runners]\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_runner.py:165\u001b[39m, in \u001b[36mRunner._run_iteration.<locals>._deliver_messages.<locals>._deliver_message_inner\u001b[39m\u001b[34m(edge_runner, message)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_deliver_message_inner\u001b[39m(edge_runner: EdgeRunner, message: Message) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    164\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Inner loop to deliver a single message through an edge runner.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m edge_runner.send_message(message, \u001b[38;5;28mself\u001b[39m._shared_state, \u001b[38;5;28mself\u001b[39m._ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_edge_runner.py:348\u001b[39m, in \u001b[36mFanInEdgeRunner.send_message\u001b[39m\u001b[34m(self, message, shared_state, ctx)\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# Execute outside the span if needed\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m execution_data:\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_on_target(\n\u001b[32m    349\u001b[39m         execution_data[\u001b[33m\"\u001b[39m\u001b[33mtarget_id\u001b[39m\u001b[33m\"\u001b[39m], execution_data[\u001b[33m\"\u001b[39m\u001b[33msource_ids\u001b[39m\u001b[33m\"\u001b[39m], execution_data[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m], shared_state, ctx\n\u001b[32m    350\u001b[39m     )\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_edge_runner.py:68\u001b[39m, in \u001b[36mEdgeRunner._execute_on_target\u001b[39m\u001b[34m(self, target_id, source_ids, message, shared_state, ctx)\u001b[39m\n\u001b[32m     65\u001b[39m target_executor = \u001b[38;5;28mself\u001b[39m._executors[target_id]\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Execute with trace context parameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m target_executor.execute(\n\u001b[32m     69\u001b[39m     message.data,\n\u001b[32m     70\u001b[39m     source_ids,  \u001b[38;5;66;03m# source_executor_ids\u001b[39;00m\n\u001b[32m     71\u001b[39m     shared_state,  \u001b[38;5;66;03m# shared_state\u001b[39;00m\n\u001b[32m     72\u001b[39m     ctx,  \u001b[38;5;66;03m# runner_context\u001b[39;00m\n\u001b[32m     73\u001b[39m     trace_contexts=message.trace_contexts,  \u001b[38;5;66;03m# Pass trace contexts\u001b[39;00m\n\u001b[32m     74\u001b[39m     source_span_ids=message.source_span_ids,  \u001b[38;5;66;03m# Pass source span IDs for linking\u001b[39;00m\n\u001b[32m     75\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_executor.py:276\u001b[39m, in \u001b[36mExecutor.execute\u001b[39m\u001b[34m(self, message, source_executor_ids, shared_state, runner_context, trace_contexts, source_span_ids)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m context.add_event(invoke_event)\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m handler(message, context)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# Surface structured executor failure before propagating\u001b[39;00m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _framework_event_origin():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/agents-demo-z2j_d0w_-py3.13/lib/python3.13/site-packages/agent_framework/_workflows/_executor.py:492\u001b[39m, in \u001b[36mhandler.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: ExecutorT, message: Any, ctx: ContextT) -> Any:\n\u001b[32m    491\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrapper function to call the handler.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, message, ctx)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 248\u001b[39m, in \u001b[36mImprovedChunksAgregatorExec.run\u001b[39m\u001b[34m(self, detected_secrets, ctx)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;129m@handler\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, detected_secrets: \u001b[38;5;28mlist\u001b[39m[SecretsDetectorExecutorResponse] ,ctx: WorkflowContext[\u001b[38;5;28;01mNone\u001b[39;00m]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    247\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sends input test chunks\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     sem = asyncio.Semaphore(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_concurrency\u001b[49m)\n\u001b[32m    249\u001b[39m     tasks: \u001b[38;5;28mlist\u001b[39m[asyncio.Task] = []\n\u001b[32m    250\u001b[39m     filtered_nonempty = [secret \u001b[38;5;28;01mfor\u001b[39;00m secret \u001b[38;5;129;01min\u001b[39;00m detected_secrets \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m secret.is_empty()]\n",
      "\u001b[31mAttributeError\u001b[39m: 'ImprovedChunksAgregatorExec' object has no attribute 'max_concurrency'"
     ]
    }
   ],
   "source": [
    "async for event in workflow.run_stream(\"\"):\n",
    "    match event:\n",
    "        case CustomResponseEvent() as output:\n",
    "            print(f\"Workflow finished\")\n",
    "        case ExecutorInvokedEvent() as invoke:\n",
    "            print(f\"Starting {invoke.executor_id}\")\n",
    "        case ExecutorCompletedEvent() as complete:\n",
    "            print(f\"Completed {complete.executor_id}: {complete.data}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-demo-z2j_d0w_-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
